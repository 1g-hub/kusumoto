{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWngv4jijzndeMk70IZtOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c5e514ef05b4699a551d651ace3ff78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e96d97da996d40eea0031de2e5a4ebf5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9424c2015973428e88a2230e7aae9ea9",
              "IPY_MODEL_0624120496334afb8051be8dc0d38af2"
            ]
          }
        },
        "e96d97da996d40eea0031de2e5a4ebf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9424c2015973428e88a2230e7aae9ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_469f4d5e6dd04ced92cbf6e8ec3b0d2a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 479,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 479,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2c06bc8c7fa447aaf0705dee522cb2c"
          }
        },
        "0624120496334afb8051be8dc0d38af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_acef8b34d38f427e9b46997fa889f382",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 479/479 [00:00&lt;00:00, 653B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a054e58e0caf4fe6b9e51b102fed0594"
          }
        },
        "469f4d5e6dd04ced92cbf6e8ec3b0d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2c06bc8c7fa447aaf0705dee522cb2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acef8b34d38f427e9b46997fa889f382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a054e58e0caf4fe6b9e51b102fed0594": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae823c846a4248e0b31d8e7b70ce05e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c822d7bc7c14f999809d90285c149ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5299dace0a14abaa10012471e34c251",
              "IPY_MODEL_a275d1dd4d5349b48e8deefd5a5822bc"
            ]
          }
        },
        "0c822d7bc7c14f999809d90285c149ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5299dace0a14abaa10012471e34c251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4495279bec974b939138a23bd9eb26fe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445021143,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445021143,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0987acde780c493ea21787d4268c7239"
          }
        },
        "a275d1dd4d5349b48e8deefd5a5822bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8572a47628dd4a3ab8d665a8ca4802aa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:16&lt;00:00, 27.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c30ca5bdd0cc4bacb55382893c84a426"
          }
        },
        "4495279bec974b939138a23bd9eb26fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0987acde780c493ea21787d4268c7239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8572a47628dd4a3ab8d665a8ca4802aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c30ca5bdd0cc4bacb55382893c84a426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c537a5dd2aec447e85fc4a927ec74992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8cbeb3ba78f44b39834255ecf3c6646",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05ec0a5ccb47461f9adff019cdc45c86",
              "IPY_MODEL_5fd09a8393624392aab486a259cc1137"
            ]
          }
        },
        "d8cbeb3ba78f44b39834255ecf3c6646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05ec0a5ccb47461f9adff019cdc45c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ee7cd1eb83e41e38a440b3a75109a3a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 257706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 257706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75c5a75e8d774763a2d641ef771df115"
          }
        },
        "5fd09a8393624392aab486a259cc1137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f68a33c972274eef9396a9eb3bb4cac1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 258k/258k [00:01&lt;00:00, 170kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9818ffbb6efa483e8d597d0cd04df9c2"
          }
        },
        "1ee7cd1eb83e41e38a440b3a75109a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75c5a75e8d774763a2d641ef771df115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f68a33c972274eef9396a9eb3bb4cac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9818ffbb6efa483e8d597d0cd04df9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6730de97da364d93904a7b5be27cbe64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fbe892244cf64bce8297d258cf0f2e53",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5083306be27419bba3bebd36f1a749b",
              "IPY_MODEL_eb9e826e0a4242918a6c22ccd50a9930"
            ]
          }
        },
        "fbe892244cf64bce8297d258cf0f2e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5083306be27419bba3bebd36f1a749b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5f7accc633534257947a19523fffe22f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 110,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 110,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0fa8301d190f473bbe4423f37e242efe"
          }
        },
        "eb9e826e0a4242918a6c22ccd50a9930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8538c9d17eb44ab4a25eddc8e5e119f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110/110 [00:00&lt;00:00, 1.32kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0dead5294094939a855fc34ff35d951"
          }
        },
        "5f7accc633534257947a19523fffe22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0fa8301d190f473bbe4423f37e242efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8538c9d17eb44ab4a25eddc8e5e119f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0dead5294094939a855fc34ff35d951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc59c279be374927805c530d628251e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e18fbdad9674121a9e5df03c134dd27",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f1f4ac17324437081450c1af758c01c",
              "IPY_MODEL_870409c31eac4b47832de8ed9e58be01"
            ]
          }
        },
        "5e18fbdad9674121a9e5df03c134dd27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f1f4ac17324437081450c1af758c01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d0135c9edf904090ba0663a3a6137916",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 257706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 257706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_260bc3015d1c4155989afb13a2988af4"
          }
        },
        "870409c31eac4b47832de8ed9e58be01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae14839aa55b4e7ea7d544f4a9918067",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 258k/258k [00:01&lt;00:00, 216kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f438255a71b040bdbae26506207b8144"
          }
        },
        "d0135c9edf904090ba0663a3a6137916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "260bc3015d1c4155989afb13a2988af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae14839aa55b4e7ea7d544f4a9918067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f438255a71b040bdbae26506207b8144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80eeaa4a4b6a4f2bb80bcb8567a5e97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92e342aceee2469ea7b1882fee7f5255",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e20d1856b9a84756858208743125230d",
              "IPY_MODEL_ae1b0e06db764ce78e22e1c828f642d2"
            ]
          }
        },
        "92e342aceee2469ea7b1882fee7f5255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e20d1856b9a84756858208743125230d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_879c4a8ca4284579b150d806352851f3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 110,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 110,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67fd3ab20b65400aacb90855d45ca656"
          }
        },
        "ae1b0e06db764ce78e22e1c828f642d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04ea7d7e04424602a7cc2fc1723c7c2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110/110 [00:00&lt;00:00, 1.32kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85a20697b60643689f61e2cc6128e434"
          }
        },
        "879c4a8ca4284579b150d806352851f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67fd3ab20b65400aacb90855d45ca656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04ea7d7e04424602a7cc2fc1723c7c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85a20697b60643689f61e2cc6128e434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuuki-kusumoto/kusumoto/blob/master/multi_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RhqzHpaU3Z1",
        "outputId": "313fa29d-d500-4623-e481-164133974625"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul  7 02:32:05 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R33fK3YUA5jV",
        "outputId": "ea4d8436-d370-450f-f80c-50c346e67b86"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 6.8MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3opCrjrJA37N",
        "outputId": "9ad22c14-dae6-49e9-cea6-06722827e543"
      },
      "source": [
        "!apt install aptitude swig"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n",
            "  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n",
            "  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n",
            "  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n",
            "  libwww-perl xapian-tools swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n",
            "  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n",
            "  libhttp-message-perl libio-html-perl libio-string-perl\n",
            "  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n",
            "  libsub-name-perl libtimedate-perl liburi-perl libxapian30 swig swig3.0\n",
            "0 upgraded, 23 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,978 kB of archives.\n",
            "After this operation, 21.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 4,978 kB in 2s (2,492 kB/s)\n",
            "Selecting previously unselected package aptitude-common.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n",
            "Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n",
            "Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n",
            "Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Selecting previously unselected package libcwidget3v5:amd64.\n",
            "Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n",
            "Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Selecting previously unselected package libxapian30:amd64.\n",
            "Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aptitude.\n",
            "Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n",
            "Unpacking aptitude (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libcgi-pm-perl.\n",
            "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
            "Unpacking libcgi-pm-perl (4.38-1) ...\n",
            "Selecting previously unselected package libfcgi-perl.\n",
            "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
            "Unpacking libfcgi-perl (0.78-2build1) ...\n",
            "Selecting previously unselected package libcgi-fast-perl.\n",
            "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
            "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
            "Selecting previously unselected package libsub-name-perl.\n",
            "Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
            "Unpacking libsub-name-perl (0.21-1build1) ...\n",
            "Selecting previously unselected package libclass-accessor-perl.\n",
            "Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n",
            "Unpacking libclass-accessor-perl (0.51-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libio-string-perl.\n",
            "Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n",
            "Unpacking libio-string-perl (1.08-3) ...\n",
            "Selecting previously unselected package libparse-debianchangelog-perl.\n",
            "Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n",
            "Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Selecting previously unselected package swig3.0.\n",
            "Preparing to unpack .../21-swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../22-swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libcgi-pm-perl (4.38-1) ...\n",
            "Setting up libio-string-perl (1.08-3) ...\n",
            "Setting up libsub-name-perl (0.21-1build1) ...\n",
            "Setting up libfcgi-perl (0.78-2build1) ...\n",
            "Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Setting up libclass-accessor-perl (0.51-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
            "Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Setting up aptitude (0.8.10-6ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a8ii-gFA_Tg",
        "outputId": "b57f7c7f-ca59-4902-cbc0-cb0e7b974427"
      },
      "source": [
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n",
            "0 packages upgraded, 11 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n",
            "Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
            "Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
            "Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 29.3 MB in 3s (10.3 MB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 162022 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-jumandic-utf8.\n",
            "Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-jumandic.\n",
            "Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Compiling Juman dictionary for Mecab.\n",
            "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
            "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
            "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
            "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
            "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
            "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
            "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
            "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
            "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
            "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
            "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
            "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
            "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
            "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
            "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
            "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "                            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duc4HlAwBCo8",
        "outputId": "cfbc7175-3326-4568-c94c-54b2b2ba6ad9"
      },
      "source": [
        "pip install MeCab"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting MeCab\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/60/7059e1f60969544c45b2c3edacffe1b07932db9ee623a646d06d2173568d/mecab-0.996.3.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 51kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: MeCab\n",
            "  Building wheel for MeCab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MeCab: filename=mecab-0.996.3-cp37-cp37m-linux_x86_64.whl size=141795 sha256=51ed132fcfb4cf24a6259d6f9e8ce1f91521653f524bbc0cec11fe2767686e8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/95/18/2c71c144b3c41ba34f532aa8b6531d1d93980a71db8b3d200b\n",
            "Successfully built MeCab\n",
            "Installing collected packages: MeCab\n",
            "Successfully installed MeCab-0.996.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eYt8DylBC44",
        "outputId": "7f222120-6c6e-43c6-d6d3-93d1fe5e069b"
      },
      "source": [
        "pip install mecab-python3"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mecab-python3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/4a/6ab07c8c166753282571ef3c51362a0fd8c00ff029c4f38c0a042184c32f/mecab_python3-1.0.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (488kB)\n",
            "\r\u001b[K     |▊                               | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 19.6MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 15.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 6.7MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 102kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 112kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 122kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 133kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 143kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 153kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 163kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 174kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 184kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 194kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 204kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 215kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 225kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 235kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 245kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 256kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 266kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 276kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 286kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 296kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 307kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 317kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 327kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 337kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 348kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 358kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 368kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 378kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 389kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 399kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 409kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 419kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 430kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 440kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 450kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 460kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 471kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 481kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 7.3MB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj6YA-6xBDF4",
        "outputId": "8e4db420-d701-40e2-b97c-e6fd7d8b23e0"
      },
      "source": [
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mecab-ipadic-neologd'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlHAzbV2BDTp",
        "outputId": "c713ad8f-b577-4e5a-a704-1ca43853a810"
      },
      "source": [
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : Check the existance of libraries\n",
            "[install-mecab-ipadic-NEologd] :     find => ok\n",
            "[install-mecab-ipadic-NEologd] :     sort => ok\n",
            "[install-mecab-ipadic-NEologd] :     head => ok\n",
            "[install-mecab-ipadic-NEologd] :     cut => ok\n",
            "[install-mecab-ipadic-NEologd] :     egrep => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab-config => ok\n",
            "[install-mecab-ipadic-NEologd] :     make => ok\n",
            "[install-mecab-ipadic-NEologd] :     curl => ok\n",
            "[install-mecab-ipadic-NEologd] :     sed => ok\n",
            "[install-mecab-ipadic-NEologd] :     cat => ok\n",
            "[install-mecab-ipadic-NEologd] :     diff => ok\n",
            "[install-mecab-ipadic-NEologd] :     tar => ok\n",
            "[install-mecab-ipadic-NEologd] :     unxz => ok\n",
            "[install-mecab-ipadic-NEologd] :     xargs => ok\n",
            "[install-mecab-ipadic-NEologd] :     grep => ok\n",
            "[install-mecab-ipadic-NEologd] :     iconv => ok\n",
            "[install-mecab-ipadic-NEologd] :     patch => ok\n",
            "[install-mecab-ipadic-NEologd] :     which => ok\n",
            "[install-mecab-ipadic-NEologd] :     file => ok\n",
            "[install-mecab-ipadic-NEologd] :     openssl => ok\n",
            "[install-mecab-ipadic-NEologd] :     awk => ok\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd is already up-to-date\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd will be install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Make mecab-ipadic-NEologd\n",
            "[make-mecab-ipadic-NEologd] : Start..\n",
            "[make-mecab-ipadic-NEologd] : Check local seed directory\n",
            "[make-mecab-ipadic-NEologd] : Check local seed file\n",
            "[make-mecab-ipadic-NEologd] : Check local build directory\n",
            "[make-mecab-ipadic-NEologd] : create /content/mecab-ipadic-neologd/libexec/../build\n",
            "[make-mecab-ipadic-NEologd] : Download original mecab-ipadic file\n",
            "[make-mecab-ipadic-NEologd] : Try to access to https://ja.osdn.net\n",
            "[make-mecab-ipadic-NEologd] : Try to download from https://ja.osdn.net/frs/g_redir.php?m=kent&f=mecab%2Fmecab-ipadic%2F2.7.0-20070801%2Fmecab-ipadic-2.7.0-20070801.tar.gz\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 11.6M  100 11.6M    0     0  2551k      0  0:00:04  0:00:04 --:--:-- 3180k\n",
            "Hash value of /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801.tar.gz matched\n",
            "[make-mecab-ipadic-NEologd] : Decompress original mecab-ipadic file\n",
            "mecab-ipadic-2.7.0-20070801/\n",
            "mecab-ipadic-2.7.0-20070801/README\n",
            "mecab-ipadic-2.7.0-20070801/AUTHORS\n",
            "mecab-ipadic-2.7.0-20070801/COPYING\n",
            "mecab-ipadic-2.7.0-20070801/ChangeLog\n",
            "mecab-ipadic-2.7.0-20070801/INSTALL\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.am\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.in\n",
            "mecab-ipadic-2.7.0-20070801/NEWS\n",
            "mecab-ipadic-2.7.0-20070801/aclocal.m4\n",
            "mecab-ipadic-2.7.0-20070801/config.guess\n",
            "mecab-ipadic-2.7.0-20070801/config.sub\n",
            "mecab-ipadic-2.7.0-20070801/configure\n",
            "mecab-ipadic-2.7.0-20070801/configure.in\n",
            "mecab-ipadic-2.7.0-20070801/install-sh\n",
            "mecab-ipadic-2.7.0-20070801/missing\n",
            "mecab-ipadic-2.7.0-20070801/mkinstalldirs\n",
            "mecab-ipadic-2.7.0-20070801/Adj.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adnominal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adverb.csv\n",
            "mecab-ipadic-2.7.0-20070801/Auxil.csv\n",
            "mecab-ipadic-2.7.0-20070801/Conjunction.csv\n",
            "mecab-ipadic-2.7.0-20070801/Filler.csv\n",
            "mecab-ipadic-2.7.0-20070801/Interjection.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adjv.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adverbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.demonst.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.nai.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.name.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.number.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.org.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.place.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.proper.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.verbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp-col.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp.csv\n",
            "mecab-ipadic-2.7.0-20070801/Prefix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Suffix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Symbol.csv\n",
            "mecab-ipadic-2.7.0-20070801/Verb.csv\n",
            "mecab-ipadic-2.7.0-20070801/char.def\n",
            "mecab-ipadic-2.7.0-20070801/feature.def\n",
            "mecab-ipadic-2.7.0-20070801/left-id.def\n",
            "mecab-ipadic-2.7.0-20070801/matrix.def\n",
            "mecab-ipadic-2.7.0-20070801/pos-id.def\n",
            "mecab-ipadic-2.7.0-20070801/rewrite.def\n",
            "mecab-ipadic-2.7.0-20070801/right-id.def\n",
            "mecab-ipadic-2.7.0-20070801/unk.def\n",
            "mecab-ipadic-2.7.0-20070801/dicrc\n",
            "mecab-ipadic-2.7.0-20070801/RESULT\n",
            "[make-mecab-ipadic-NEologd] : Configure custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200910\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for working aclocal-1.4... missing\n",
            "checking for working autoconf... missing\n",
            "checking for working automake-1.4... missing\n",
            "checking for working autoheader... missing\n",
            "checking for working makeinfo... missing\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking for mecab-config... /usr/bin/mecab-config\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "[make-mecab-ipadic-NEologd] : Encode the character encoding of system dictionary resources from EUC_JP to UTF-8\n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adj.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adjv.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Prefix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp-col.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adverb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.name.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adverbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Suffix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.verbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.org.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Verb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Filler.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.number.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.nai.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.demonst.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Symbol.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Auxil.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adnominal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.place.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Conjunction.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Interjection.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.proper.csv \n",
            "rm ./Adj.csv \n",
            "rm ./Noun.adjv.csv \n",
            "rm ./Prefix.csv \n",
            "rm ./Postp-col.csv \n",
            "rm ./Adverb.csv \n",
            "rm ./Noun.csv \n",
            "rm ./Noun.others.csv \n",
            "rm ./Noun.name.csv \n",
            "rm ./Noun.adverbal.csv \n",
            "rm ./Suffix.csv \n",
            "rm ./Postp.csv \n",
            "rm ./Noun.verbal.csv \n",
            "rm ./Noun.org.csv \n",
            "rm ./Verb.csv \n",
            "rm ./Filler.csv \n",
            "rm ./Noun.number.csv \n",
            "rm ./Others.csv \n",
            "rm ./Noun.nai.csv \n",
            "rm ./Noun.demonst.csv \n",
            "rm ./Symbol.csv \n",
            "rm ./Auxil.csv \n",
            "rm ./Adnominal.csv \n",
            "rm ./Noun.place.csv \n",
            "rm ./Conjunction.csv \n",
            "rm ./Interjection.csv \n",
            "rm ./Noun.proper.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./pos-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./left-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./char.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./rewrite.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./matrix.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./feature.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./unk.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./right-id.def \n",
            "rm ./pos-id.def \n",
            "rm ./left-id.def \n",
            "rm ./char.def \n",
            "rm ./rewrite.def \n",
            "rm ./matrix.def \n",
            "rm ./feature.def \n",
            "rm ./unk.def \n",
            "rm ./right-id.def \n",
            "mv ./Noun.number.csv.utf8 ./Noun.number.csv \n",
            "mv ./unk.def.utf8 ./unk.def \n",
            "mv ./Noun.name.csv.utf8 ./Noun.name.csv \n",
            "mv ./feature.def.utf8 ./feature.def \n",
            "mv ./Adverb.csv.utf8 ./Adverb.csv \n",
            "mv ./Noun.adjv.csv.utf8 ./Noun.adjv.csv \n",
            "mv ./Noun.place.csv.utf8 ./Noun.place.csv \n",
            "mv ./Auxil.csv.utf8 ./Auxil.csv \n",
            "mv ./Others.csv.utf8 ./Others.csv \n",
            "mv ./Filler.csv.utf8 ./Filler.csv \n",
            "mv ./right-id.def.utf8 ./right-id.def \n",
            "mv ./Conjunction.csv.utf8 ./Conjunction.csv \n",
            "mv ./Noun.verbal.csv.utf8 ./Noun.verbal.csv \n",
            "mv ./Adj.csv.utf8 ./Adj.csv \n",
            "mv ./Postp.csv.utf8 ./Postp.csv \n",
            "mv ./Noun.demonst.csv.utf8 ./Noun.demonst.csv \n",
            "mv ./Interjection.csv.utf8 ./Interjection.csv \n",
            "mv ./Adnominal.csv.utf8 ./Adnominal.csv \n",
            "mv ./Noun.others.csv.utf8 ./Noun.others.csv \n",
            "mv ./Verb.csv.utf8 ./Verb.csv \n",
            "mv ./matrix.def.utf8 ./matrix.def \n",
            "mv ./Prefix.csv.utf8 ./Prefix.csv \n",
            "mv ./Symbol.csv.utf8 ./Symbol.csv \n",
            "mv ./Noun.nai.csv.utf8 ./Noun.nai.csv \n",
            "mv ./Noun.adverbal.csv.utf8 ./Noun.adverbal.csv \n",
            "mv ./char.def.utf8 ./char.def \n",
            "mv ./Suffix.csv.utf8 ./Suffix.csv \n",
            "mv ./Noun.proper.csv.utf8 ./Noun.proper.csv \n",
            "mv ./Noun.csv.utf8 ./Noun.csv \n",
            "mv ./Noun.org.csv.utf8 ./Noun.org.csv \n",
            "mv ./pos-id.def.utf8 ./pos-id.def \n",
            "mv ./left-id.def.utf8 ./left-id.def \n",
            "mv ./Postp-col.csv.utf8 ./Postp-col.csv \n",
            "mv ./rewrite.def.utf8 ./rewrite.def \n",
            "[make-mecab-ipadic-NEologd] : Fix yomigana field of IPA dictionary\n",
            "patching file Noun.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Verb.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.adverbal.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.others.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Prefix.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.demonst.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "[make-mecab-ipadic-NEologd] : Copy user dictionary resource\n",
            "[make-mecab-ipadic-NEologd] : Install adverb entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adverb-dict-seed.20150623.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install interjection entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-interjection-dict-seed.20170216.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-common-noun-ortho-variant-dict-seed.20170228.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-proper-noun-ortho-variant-dict-seed.20161110.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install entries of orthographic variant of a noun used as verb form using /content/mecab-ipadic-neologd/libexec/../seed/neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install frequent adjective orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-std-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent adjective orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-exp-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install adjective verb orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-verb-dict-seed.20160324.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent datetime representation entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-date-time-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent quantity representation entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-quantity-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install entries of ill formed words using /content/mecab-ipadic-neologd/libexec/../seed/neologd-ill-formed-words-dict-seed.20170127.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Re-Index system dictionary\n",
            "reading ./unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "reading ./Adj.csv ... 27210\n",
            "reading ./Noun.adjv.csv ... 3328\n",
            "reading ./Prefix.csv ... 224\n",
            "reading ./Postp-col.csv ... 91\n",
            "reading ./Adverb.csv ... 3032\n",
            "reading ./neologd-common-noun-ortho-variant-dict-seed.20170228.csv ... 152869\n",
            "reading ./Noun.csv ... 60734\n",
            "reading ./Noun.others.csv ... 153\n",
            "reading ./neologd-adjective-exp-dict-seed.20151126.csv ... 1051146\n",
            "reading ./neologd-adjective-std-dict-seed.20151126.csv ... 507812\n",
            "reading ./neologd-interjection-dict-seed.20170216.csv ... 4701\n",
            "reading ./neologd-proper-noun-ortho-variant-dict-seed.20161110.csv ... 138379\n",
            "reading ./Noun.name.csv ... 34215\n",
            "reading ./neologd-quantity-infreq-dict-seed.20190415.csv ... 229216\n",
            "reading ./mecab-user-dict-seed.20200910.csv ... 3224584\n",
            "reading ./neologd-adjective-verb-dict-seed.20160324.csv ... 20268\n",
            "reading ./Noun.adverbal.csv ... 808\n",
            "reading ./neologd-adverb-dict-seed.20150623.csv ... 139792\n",
            "reading ./Suffix.csv ... 1448\n",
            "reading ./Postp.csv ... 146\n",
            "reading ./Noun.verbal.csv ... 12150\n",
            "reading ./neologd-date-time-infreq-dict-seed.20190415.csv ... 16866\n",
            "reading ./Noun.org.csv ... 17149\n",
            "reading ./Verb.csv ... 130750\n",
            "reading ./Filler.csv ... 19\n",
            "reading ./Noun.number.csv ... 42\n",
            "reading ./Others.csv ... 2\n",
            "reading ./neologd-ill-formed-words-dict-seed.20170127.csv ... 60616\n",
            "reading ./Noun.nai.csv ... 42\n",
            "reading ./Noun.demonst.csv ... 120\n",
            "reading ./Symbol.csv ... 208\n",
            "reading ./Auxil.csv ... 199\n",
            "reading ./Adnominal.csv ... 135\n",
            "reading ./neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv ... 26058\n",
            "reading ./Noun.place.csv ... 73194\n",
            "reading ./Conjunction.csv ... 171\n",
            "reading ./Interjection.csv ... 252\n",
            "reading ./Noun.proper.csv ... 27493\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "[make-mecab-ipadic-NEologd] : Make custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200910\n",
            "make: Nothing to be done for 'all'.\n",
            "[make-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : Get results of tokenize test\n",
            "[test-mecab-ipadic-NEologd] : Start..\n",
            "[test-mecab-ipadic-NEologd] : Replace timestamp from 'git clone' date to 'git commit' date\n",
            "[test-mecab-ipadic-NEologd] : Get buzz phrases\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 32137    0 32137    0     0  57800      0 --:--:-- --:--:-- --:--:-- 57696\n",
            "[test-mecab-ipadic-NEologd] : Get difference between default system dictionary and mecab-ipadic-NEologd\n",
            "[test-mecab-ipadic-NEologd] : Something wrong. You shouldn't install mecab-ipadic-NEologd yet.\n",
            "[test-mecab-ipadic-NEologd] : Finish..\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Please check the list of differences in the upper part.\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Do you want to install mecab-ipadic-NEologd? Type yes or no.\n",
            "[install-mecab-ipadic-NEologd] : OK. Let's install mecab-ipadic-NEologd.\n",
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : /usr/lib/x86_64-linux-gnu/mecab/dic isn't current user's directory\n",
            "[install-mecab-ipadic-NEologd] : Sudo make install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "make[1]: Entering directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200910'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            "/bin/bash ./mkinstalldirs /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "mkdir /usr/lib/x86_64-linux-gnu/mecab\n",
            "mkdir /usr/lib/x86_64-linux-gnu/mecab/dic\n",
            "mkdir /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            " /usr/bin/install -c -m 644 ./matrix.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/matrix.bin\n",
            " /usr/bin/install -c -m 644 ./char.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/char.bin\n",
            " /usr/bin/install -c -m 644 ./sys.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/sys.dic\n",
            " /usr/bin/install -c -m 644 ./unk.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/unk.dic\n",
            " /usr/bin/install -c -m 644 ./left-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/left-id.def\n",
            " /usr/bin/install -c -m 644 ./right-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/right-id.def\n",
            " /usr/bin/install -c -m 644 ./rewrite.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/rewrite.def\n",
            " /usr/bin/install -c -m 644 ./pos-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/pos-id.def\n",
            " /usr/bin/install -c -m 644 ./dicrc /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/dicrc\n",
            "make[1]: Leaving directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200910'\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Install completed.\n",
            "[install-mecab-ipadic-NEologd] : When you use MeCab, you can set '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd' as a value of '-d' option of MeCab.\n",
            "[install-mecab-ipadic-NEologd] : Usage of mecab-ipadic-NEologd is here.\n",
            "Usage:\n",
            "    $ mecab -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd ...\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbwfqvtFBDkC"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                           shell=True).communicate()[0]).decode('utf-8')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX93qn7kBD_c",
        "outputId": "02ac2da1-ec35-4e10-98b2-26201779e602"
      },
      "source": [
        "pip install neologdn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting neologdn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/46/0bb6c64ff8b9c549a3fbdff68240155fb5f938a2563ce5396278973919f0/neologdn-0.5.1.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20kB 27.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 30kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: neologdn\n",
            "  Building wheel for neologdn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neologdn: filename=neologdn-0.5.1-cp37-cp37m-linux_x86_64.whl size=172952 sha256=097cd3c70014b09695decd70c1fa96e81980c67ac7f240d0d583317074bb83a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/b8/03/6c4210244645d18770a3314cbdd853879322f42d249cb2b4b0\n",
            "Successfully built neologdn\n",
            "Installing collected packages: neologdn\n",
            "Successfully installed neologdn-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O-ochNHBEO8",
        "outputId": "d0c30801-186e-4471-d81a-266f9ae6d444"
      },
      "source": [
        "pip install ipadic"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipadic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/4e/c459f94d62a0bef89f866857bc51b9105aff236b83928618315b41a26b7b/ipadic-1.0.0.tar.gz (13.4MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4MB 229kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-cp37-none-any.whl size=13556725 sha256=e25d25c5ad0cc4b039d506619b4b616b29dcec804df6c8335d35af450881555c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/00/d1/0c094a0ce58a77199a0c5801f0ecf510c80f0ecbec27f07d2c\n",
            "Successfully built ipadic\n",
            "Installing collected packages: ipadic\n",
            "Successfully installed ipadic-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlNZJ7MFBEdQ",
        "outputId": "ef34d36d-615d-4cd9-eaa0-9a591be2f55d"
      },
      "source": [
        "pip install mecab-python3"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.7/dist-packages (1.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUE1TK5tBZ0W",
        "outputId": "a85a7d42-9b98-4441-d827-fbf98be966e0"
      },
      "source": [
        "pip install unidic-lite"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidic-lite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/2b/8cf7514cb57d028abcef625afa847d60ff1ffbf0049c36b78faa7c35046f/unidic-lite-1.0.8.tar.gz (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 62kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: unidic-lite\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-cp37-none-any.whl size=47658838 sha256=5c4f06a6a93544f07ad65d01b59d66285372fd1f4cebe2e667407ef2ce62ea48\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/48/8d/b66d8361a27f58f41ec86640e4fd2640de0403a6367511eab7\n",
            "Successfully built unidic-lite\n",
            "Installing collected packages: unidic-lite\n",
            "Successfully installed unidic-lite-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRYTwO6WBZw0",
        "outputId": "9488bfec-56ab-460d-cc19-9a962f03f75e"
      },
      "source": [
        "# MeCabとtransformersを用意する\n",
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "# 以下で報告があるようにmecab-python3のバージョンを0.996.5にしないとtokezerで落ちる\n",
        "# https://stackoverflow.com/questions/62860717/huggingface-for-japanese-tokenizer\n",
        "!pip install mecab-python3==0.996.5\n",
        "!pip install unidic-lite # これないとMeCab実行時にエラーで落ちる\n",
        "!pip install transformers"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "swig is already the newest version (3.0.12-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n",
            "Collecting mecab-python3==0.996.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/62/f1e4ffba2f904b8998da8df4372d70cf4dad6301b94f4f9e50e9aea1b82e/mecab_python3-0.996.5-cp37-cp37m-manylinux2010_x86_64.whl (17.1MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1MB 188kB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "  Found existing installation: mecab-python3 1.0.4\n",
            "    Uninstalling mecab-python3-1.0.4:\n",
            "      Successfully uninstalled mecab-python3-1.0.4\n",
            "Successfully installed mecab-python3-0.996.5\n",
            "Requirement already satisfied: unidic-lite in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x75S-XvoBZuJ",
        "outputId": "3600c62c-18df-453e-939d-3137d15b64ad"
      },
      "source": [
        "pip install \"transformers==2.5.1\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.19.5)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 33.0MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/20/e579b5d7b72162461236133b837eae51d4fab290f3286e020b3be544447f/boto3-1.17.106-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.106\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/14/3e13e2db6a8f2690d53d202baa1390d0c0141c9577d5c7fca751fea40c5e/botocore-1.20.106-py2.py3-none-any.whl (7.7MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 49.6MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.106->boto3->transformers==2.5.1) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.106 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, tokenizers, jmespath, botocore, s3transfer, boto3, transformers\n",
            "  Found existing installation: tokenizers 0.10.3\n",
            "    Uninstalling tokenizers-0.10.3:\n",
            "      Successfully uninstalled tokenizers-0.10.3\n",
            "  Found existing installation: transformers 4.8.2\n",
            "    Uninstalling transformers-4.8.2:\n",
            "      Successfully uninstalled transformers-4.8.2\n",
            "Successfully installed boto3-1.17.106 botocore-1.20.106 jmespath-0.10.0 s3transfer-0.4.2 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhQLbD9yKe0e"
      },
      "source": [
        "import torch\n",
        "from transformers.modeling_bert import BertModel\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8tdeog2BZpE",
        "outputId": "1d3d1dcd-4e59-4491-c872-b16c0c0526a7"
      },
      "source": [
        "! curl http://www.cl.ecei.tohoku.ac.jp/resources/sent_lex/pn.csv.m3.120408.trim > pn.csv"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  676k  100  676k    0     0   555k      0  0:00:01  0:00:01 --:--:--  556k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216,
          "referenced_widgets": [
            "4c5e514ef05b4699a551d651ace3ff78",
            "e96d97da996d40eea0031de2e5a4ebf5",
            "9424c2015973428e88a2230e7aae9ea9",
            "0624120496334afb8051be8dc0d38af2",
            "469f4d5e6dd04ced92cbf6e8ec3b0d2a",
            "d2c06bc8c7fa447aaf0705dee522cb2c",
            "acef8b34d38f427e9b46997fa889f382",
            "a054e58e0caf4fe6b9e51b102fed0594",
            "ae823c846a4248e0b31d8e7b70ce05e5",
            "0c822d7bc7c14f999809d90285c149ec",
            "a5299dace0a14abaa10012471e34c251",
            "a275d1dd4d5349b48e8deefd5a5822bc",
            "4495279bec974b939138a23bd9eb26fe",
            "0987acde780c493ea21787d4268c7239",
            "8572a47628dd4a3ab8d665a8ca4802aa",
            "c30ca5bdd0cc4bacb55382893c84a426",
            "c537a5dd2aec447e85fc4a927ec74992",
            "d8cbeb3ba78f44b39834255ecf3c6646",
            "05ec0a5ccb47461f9adff019cdc45c86",
            "5fd09a8393624392aab486a259cc1137",
            "1ee7cd1eb83e41e38a440b3a75109a3a",
            "75c5a75e8d774763a2d641ef771df115",
            "f68a33c972274eef9396a9eb3bb4cac1",
            "9818ffbb6efa483e8d597d0cd04df9c2",
            "6730de97da364d93904a7b5be27cbe64",
            "fbe892244cf64bce8297d258cf0f2e53",
            "c5083306be27419bba3bebd36f1a749b",
            "eb9e826e0a4242918a6c22ccd50a9930",
            "5f7accc633534257947a19523fffe22f",
            "0fa8301d190f473bbe4423f37e242efe",
            "8538c9d17eb44ab4a25eddc8e5e119f3",
            "d0dead5294094939a855fc34ff35d951"
          ]
        },
        "id": "s_nuEq9YBZmG",
        "outputId": "13dd651e-2dd1-4557-e2cc-9e5f5f1f2e32"
      },
      "source": [
        "import transformers\n",
        "from transformers.modeling_bert import BertModel\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
        "\n",
        "model = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "\n",
        "# model_nameはここから取得(cf. https://huggingface.co/transformers/pretrained_models.html)\n",
        "model_name = \"cl-tohoku/bert-base-japanese\"\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c5e514ef05b4699a551d651ace3ff78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=479.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae823c846a4248e0b31d8e7b70ce05e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445021143.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c537a5dd2aec447e85fc4a927ec74992",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=257706.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6730de97da364d93904a7b5be27cbe64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=110.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2k2dVA0D9A4"
      },
      "source": [
        "CSVデータの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "8JNqnMPlBZhQ",
        "outputId": "d70671d5-d93a-4049-9a0d-bc6bcf318910"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('travel.csv', index_col=0)\n",
        "df1.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c0ef49c48fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'travel.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'travel.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQO8wluoBZVU"
      },
      "source": [
        "df1.columns=['text','breakfast_po',\t'breakfast_ne',\t'dinner_po',\t'dinner_ne',\t'bath_po',\t'bath_ne',\t'servis_po',\t'service_ne',\t'state_po',\t'state_ne',\t'facility_po',\t'facility_ne'\t,'room_po', 'room_ne']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2zGoP35EJUP"
      },
      "source": [
        "df = df1.fillna(0)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7qVMJqtEJQj"
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AorDIs5BEYwO"
      },
      "source": [
        "データフレーム内の値をfloat型からobject型に変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNWbgo6HEJOA"
      },
      "source": [
        "df_int2 = df[['breakfast_ne',\t'dinner_po',\t'dinner_ne',\t'bath_po',\t'bath_ne',\t'servis_po',\t'service_ne',\t'state_po',\t'state_ne',\t'facility_po',\t'facility_ne'\t,'room_po', 'room_ne']].astype(int)\n",
        "print(df_int2.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tLq1EShEJLX"
      },
      "source": [
        "df_int2 = df[['breakfast_ne',\t'dinner_po',\t'dinner_ne',\t'bath_po',\t'bath_ne',\t'servis_po',\t'service_ne',\t'state_po',\t'state_ne',\t'facility_po',\t'facility_ne'\t,'room_po', 'room_ne']].astype(int)\n",
        "print(df_int2.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj7VNtEuEJIx"
      },
      "source": [
        "df_object = df_int2.astype(object)\n",
        "print(df_object.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbCIAhNSEJGb"
      },
      "source": [
        "df_int1 = df[['text','breakfast_po']]\n",
        "print(df_int1.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGde3WCBEJDW"
      },
      "source": [
        "#データフレームを結合させる\n",
        "df_concat = pd.concat([df_int1, df_object], axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HztKcmz3EJA5"
      },
      "source": [
        "df = df_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKv0SFKHEI9h"
      },
      "source": [
        "df2 = df[['text','dinner_po',\t'dinner_ne',\t'bath_po',\t'bath_ne',\t'servis_po',\t'service_ne',\t'state_po',\t'state_ne',\t'facility_po',\t'facility_ne'\t,'room_po', 'room_ne']]\n",
        "df2 = df2.sample(frac=1, random_state=127).reset_index(drop=True)\n",
        "df2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM6bNAspWoN2"
      },
      "source": [
        "x1 = df2.iloc[0][1:13]\n",
        "x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHrRiTwRV9To"
      },
      "source": [
        "ll = []\n",
        "for i in range(0, len(df2)):\n",
        "  x1 = df2.iloc[i][1:13]\n",
        "  if max(x1) == 1:\n",
        "    ll.append(i)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbmP_fjanZ3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da32dc5-3175-4f22-d7cc-682e2f932f09"
      },
      "source": [
        "len(ll)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DaNDAOwuhft"
      },
      "source": [
        "#全部が0のやつの全ラベルを格納 \n",
        "ll_0 = []\n",
        "for i in range(0, len(df2)):\n",
        "  x1 = df2.iloc[i][1:13]\n",
        "  if max(x1) == 0:\n",
        "    ll_0.append(i)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71hSGOYuwUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa54e15d-a72f-4bf5-fa8a-416a75289f7d"
      },
      "source": [
        "#全部が0のデータ数\n",
        "len(ll_0)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwAxehOgwHZ-"
      },
      "source": [
        "#全部が0のやつを省いた \n",
        "#for i in range(0, len(ll_0)):\n",
        "  #df2 = df2.drop(ll_0[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zmm4gNcyJ5E"
      },
      "source": [
        "#全部が0のやつを省いた \n",
        "#df_non0 = df2\n",
        "#df_non0.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igBsTSfffcmB"
      },
      "source": [
        "#0がないデータをcsvファイルとして保存\n",
        "#df_non0.to_csv(\"./non0_travel.csv\",index=False, encoding='cp932')\n",
        "#print(df_non0.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gPDEMMirips8",
        "outputId": "fcbcf5da-a6aa-4ac7-cedf-2714ab0befa8"
      },
      "source": [
        "import pandas as pd\n",
        "df_non0 = pd.read_csv(\"non0_travel.csv\", encoding=\"cp932\")\n",
        "df_non0"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>dinner_po</th>\n",
              "      <th>dinner_ne</th>\n",
              "      <th>bath_po</th>\n",
              "      <th>bath_ne</th>\n",
              "      <th>servis_po</th>\n",
              "      <th>service_ne</th>\n",
              "      <th>state_po</th>\n",
              "      <th>state_ne</th>\n",
              "      <th>facility_po</th>\n",
              "      <th>facility_ne</th>\n",
              "      <th>room_po</th>\n",
              "      <th>room_ne</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>立地:セブンイレブン、ドンキホーテが入ったアバンティの真横で抜群です。</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>お一人様プランも欲しいです。</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>料理は多すぎず、少なすぎず、一つ一つとても丁寧に作られていて、非常に満足しました。</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>何かをこぼしてしまっていたなら仕方ないかもしれませんけどね。</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>各階の自動販売機の大半がつり銭切れで使えなかった。</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48364</th>\n",
              "      <td>スタッフの対応もいつもニコニコしていて気持ちよかったです。</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48365</th>\n",
              "      <td>こんな言い方は失礼ですが、一人1万円強の宿泊代で、こんなに用意していただいて大丈夫なのかと思...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48366</th>\n",
              "      <td>お風呂場も綺麗でしたし、朝食も小部屋になっていて、とても良かったです。</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48367</th>\n",
              "      <td>浴場は受付が常駐されていて安心して利用できました。</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48368</th>\n",
              "      <td>心温まる応対でした。</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48369 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  ...  room_ne\n",
              "0                    立地:セブンイレブン、ドンキホーテが入ったアバンティの真横で抜群です。  ...        0\n",
              "1                                         お一人様プランも欲しいです。  ...        0\n",
              "2              料理は多すぎず、少なすぎず、一つ一つとても丁寧に作られていて、非常に満足しました。  ...        0\n",
              "3                         何かをこぼしてしまっていたなら仕方ないかもしれませんけどね。  ...        0\n",
              "4                              各階の自動販売機の大半がつり銭切れで使えなかった。  ...        0\n",
              "...                                                  ...  ...      ...\n",
              "48364                      スタッフの対応もいつもニコニコしていて気持ちよかったです。  ...        0\n",
              "48365  こんな言い方は失礼ですが、一人1万円強の宿泊代で、こんなに用意していただいて大丈夫なのかと思...  ...        0\n",
              "48366                お風呂場も綺麗でしたし、朝食も小部屋になっていて、とても良かったです。  ...        0\n",
              "48367                          浴場は受付が常駐されていて安心して利用できました。  ...        0\n",
              "48368                                         心温まる応対でした。  ...        0\n",
              "\n",
              "[48369 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WfRiSlAlH2K"
      },
      "source": [
        "df3 = df_non0[:1200]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmqrCspgEI7O",
        "outputId": "ba302739-c409-4e3e-b717-d077f552418c"
      },
      "source": [
        "# tsvファイルで保存する\n",
        "\n",
        "# 全体の2割の文章数\n",
        "len_0_2 = len(df3) // 5\n",
        "\n",
        "# 前から2割をテストデータとする\n",
        "df3[:len_0_2].to_csv(\"./test.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df3[:len_0_2].shape)\n",
        "\n",
        "# 前2割からを訓練&検証データとする\n",
        "df3[len_0_2:].to_csv(\"./train.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df3[len_0_2:].shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(240, 13)\n",
            "(960, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YEGptSgEI3_",
        "outputId": "6e62ea3f-e9c5-4488-8348-a64bf845385e"
      },
      "source": [
        "# 乱数シードの固定\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED_VALUE = 1234\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
        "random.seed(SEED_VALUE)\n",
        "np.random.seed(SEED_VALUE)\n",
        "torch.manual_seed(SEED_VALUE)  "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8a6eda60f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epaaRYk5EI1M"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "import torch\n",
        "import torchtext  # torchtextを使用"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9oCHuzJEIwM"
      },
      "source": [
        "def tokenizer_512(input_text):\n",
        "    \"\"\"torchtextのtokenizerとして扱えるように、512単語のpytorchでのencodeを定義。ここで[0]を指定し忘れないように\"\"\"\n",
        "    return tokenizer.encode(input_text, max_length=512, return_tensors='pt')[0]\n",
        "\n",
        "\n",
        "TEXT = torchtext.legacy.data.Field(sequential=True, tokenize=tokenizer_512, use_vocab=False, lower=False,include_lengths=True, batch_first=True, fix_length=512, pad_token=0)\n",
        "# 注意：tokenize=tokenizer.encodeと、.encodeをつけます。padding[PAD]のindexが0なので、0を指定します。\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL2 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL3 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL4 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL5 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL6 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL7 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL8 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL9 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL10 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL11 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#ラベルは数字なのでラベル用オブジェクトはsequential = False\n",
        "LABEL12 = torchtext.legacy.data.Field(sequential=False, use_vocab=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGs9IcfaEItL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "cc59c279be374927805c530d628251e5",
            "5e18fbdad9674121a9e5df03c134dd27",
            "6f1f4ac17324437081450c1af758c01c",
            "870409c31eac4b47832de8ed9e58be01",
            "d0135c9edf904090ba0663a3a6137916",
            "260bc3015d1c4155989afb13a2988af4",
            "ae14839aa55b4e7ea7d544f4a9918067",
            "f438255a71b040bdbae26506207b8144",
            "80eeaa4a4b6a4f2bb80bcb8567a5e97a",
            "92e342aceee2469ea7b1882fee7f5255",
            "e20d1856b9a84756858208743125230d",
            "ae1b0e06db764ce78e22e1c828f642d2",
            "879c4a8ca4284579b150d806352851f3",
            "67fd3ab20b65400aacb90855d45ca656",
            "04ea7d7e04424602a7cc2fc1723c7c2d",
            "85a20697b60643689f61e2cc6128e434"
          ]
        },
        "outputId": "e5dcaf10-c852-4380-8601-a51e6220eab5"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from transformers.modeling_bert import BertModel\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
        "\n",
        "\n",
        "# 日本語BERTの分かち書き用tokenizerを宣言\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc59c279be374927805c530d628251e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=257706.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80eeaa4a4b6a4f2bb80bcb8567a5e97a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=110.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDunrI-SFnoq"
      },
      "source": [
        "import transformers\n",
        "from transformers.modeling_bert import BertModel\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
        "\n",
        "model = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "\n",
        "# model_nameはここから取得(cf. https://huggingface.co/transformers/pretrained_models.html)\n",
        "model_name = \"cl-tohoku/bert-base-japanese\"\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo2iVT9kFnl6"
      },
      "source": [
        "# 各tsvファイルを読み込み、分かち書きをしてdatasetに\n",
        "# train_eval：61300個、test：15324個\n",
        "dataset_train_eval, dataset_test = torchtext.legacy.data.TabularDataset.splits(\n",
        "    path='.', train='train.tsv', test='test.tsv', format='tsv', fields=[('Text', TEXT), ('Label', LABEL), ('Label2', LABEL2), ('Label3', LABEL3),  ('Label4', LABEL4), ('Label5', LABEL5), ('Label6', LABEL6), ('Label7', LABEL7), ('Label8', LABEL8), ('Label9', LABEL9), ('Label10', LABEL10), ('Label11', LABEL11), ('Label12', LABEL12)])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqL0JugsFnjg",
        "outputId": "96986470-c562-49df-f17c-f1d35bdc260b"
      },
      "source": [
        "# torchtext.data.Datasetのsplit関数で訓練データと検証データを分ける\n",
        "# train_eval：61300個、test：15324個\n",
        "\n",
        "dataset_train, dataset_eval = dataset_train_eval.split(\n",
        "    split_ratio = 1 - 15324 / 61300, random_state=random.seed(1234))\n",
        "\n",
        "# datasetの長さを確認してみる\n",
        "print(dataset_train.__len__())\n",
        "print(dataset_eval.__len__())\n",
        "print(dataset_test.__len__())\n",
        "\n",
        "# datasetの中身を確認してみる\n",
        "item = next(iter(dataset_train))\n",
        "print(item.Text)\n",
        "print(\"長さ：\", len(item.Text))  "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "720\n",
            "240\n",
            "240\n",
            "tensor([    2,    35, 25703, 28458,  7914,  7914,   531,   322,    71,    26,\n",
            "         3721,     8,     3])\n",
            "長さ： 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_aQ0DvEFnfr",
        "outputId": "19065d30-fdff-4835-99f7-596cc9d4eb3e"
      },
      "source": [
        "\n",
        "print('訓練データの数', len(dataset_train_eval))\n",
        "print('1つ目の訓練データkazu', vars(dataset_train_eval[10]))\n",
        "print(vars(dataset_train_eval[0])['Label'])\n",
        "print(len(vars(dataset_train_eval[0])))\n",
        "\n",
        "# datasetの中身を文章に戻し、確認\n",
        "\n",
        "print(tokenizer.convert_ids_to_tokens(item.Text.tolist()))  # 文章"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "訓練データの数 960\n",
            "1つ目の訓練データkazu {'Text': tensor([    2,  1533,  2087, 28456,  1714,   609,     6,  5062, 28575, 18526,\n",
            "        28446,  1528, 15296, 28447, 28452,   832,  1173, 28449,     8,     3]), 'Label': '0', 'Label2': '0', 'Label3': '0', 'Label4': '0', 'Label5': '0', 'Label6': '1', 'Label7': '0', 'Label8': '0', 'Label9': '0', 'Label10': '0', 'Label11': '0', 'Label12': '0'}\n",
            "0\n",
            "13\n",
            "['[CLS]', '・', 'エアコン', '##が', '##なか', '##なか', '動', 'き', '出', 'さ', '##ない', '。', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "n96B5dVMFndX",
        "outputId": "bbab5a8e-3c70-4cb2-d3a6-1d9b7d77899d"
      },
      "source": [
        "#@title\n",
        "# 日本語BERTで扱える文章の長さは512\n",
        "import seaborn as sns\n",
        "title_length = df3['text'].map(tokenizer.encode).map(len)\n",
        "print(max(title_length))\n",
        "\n",
        "sns.distplot(title_length)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8a20aeedd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qyli0ZrFnba"
      },
      "source": [
        "# DataLoaderの作成\n",
        "\n",
        "batch_size = 12\n",
        "\n",
        "\n",
        "dl_train = torchtext.legacy.data.Iterator(\n",
        "    dataset_train, batch_size=batch_size, train=True)\n",
        "\n",
        "dl_eval = torchtext.legacy.data.Iterator(\n",
        "    dataset_eval, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "dl_test = torchtext.legacy.data.Iterator(\n",
        "    dataset_test, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": dl_train, \"val\": dl_eval}"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOOKe5F0FnZG",
        "outputId": "c4c89298-2ebd-4ce7-ac68-6852ccbc5728"
      },
      "source": [
        "# DataLoaderの動作確認 \n",
        "\n",
        "batch = next(iter(dl_test))\n",
        "print(batch)\n",
        "print(batch.Text[0].shape)\n",
        "print(batch.Label2.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 12]\n",
            "\t[.Text]:('[torch.LongTensor of size 12x512]', '[torch.LongTensor of size 12]')\n",
            "\t[.Label]:[torch.LongTensor of size 12]\n",
            "\t[.Label2]:[torch.LongTensor of size 12]\n",
            "\t[.Label3]:[torch.LongTensor of size 12]\n",
            "\t[.Label4]:[torch.LongTensor of size 12]\n",
            "\t[.Label5]:[torch.LongTensor of size 12]\n",
            "\t[.Label6]:[torch.LongTensor of size 12]\n",
            "\t[.Label7]:[torch.LongTensor of size 12]\n",
            "\t[.Label8]:[torch.LongTensor of size 12]\n",
            "\t[.Label9]:[torch.LongTensor of size 12]\n",
            "\t[.Label10]:[torch.LongTensor of size 12]\n",
            "\t[.Label11]:[torch.LongTensor of size 12]\n",
            "\t[.Label12]:[torch.LongTensor of size 12]\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2KzUrNvFnWY"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class BertForReview(nn.Module):\n",
        "    '''BERTモデルにレビュー文の2クラスを判定する部分をつなげたモデル'''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BertForReview, self).__init__()\n",
        "\n",
        "        # BERTモジュール\n",
        "        self.bert = model  # 日本語学習済みのBERTモデル\n",
        "\n",
        "        # headにポジネガ予測を追加\n",
        "        # 入力はBERTの出力特徴量の次元768、出力は12クラス\n",
        "        self.cls = nn.Linear(in_features=768, out_features=12)\n",
        "\n",
        "        # 重み初期化処理\n",
        "        nn.init.normal_(self.cls.weight, std=0.02)\n",
        "        nn.init.normal_(self.cls.bias, 0)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        '''\n",
        "        input_ids： [batch_size, sequence_length]の文章の単語IDの羅列\n",
        "        '''\n",
        "\n",
        "        # BERTの基本モデル部分の順伝搬\n",
        "        # 順伝搬させる\n",
        "        result = self.bert(input_ids)  # reult は、sequence_output, pooled_output\n",
        "\n",
        "        # sequence_outputの先頭の単語ベクトルを抜き出す\n",
        "        vec_0 = result[0]  # 最初の0がsequence_outputを示す\n",
        "        vec_0 = vec_0[:, 0, :]  # 全バッチ。先頭0番目の単語の全768要素\n",
        "        vec_0 = vec_0.view(-1, 768)  # sizeを[batch_size, hidden_size]に変換\n",
        "        output = self.cls(vec_0)  # 全結合層\n",
        "\n",
        "        return output"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiJBHxHJFnN2",
        "outputId": "51908314-1938-4a44-a6bc-0325f6e8296b"
      },
      "source": [
        "#モデル構築\n",
        "net = BertForReview()\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ネットワーク設定完了\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpypH1cxG7P6"
      },
      "source": [
        "# 勾配計算を最後のBertLayerモジュールと追加した分類アダプターのみ実行\n",
        "\n",
        "# 1. まず全部を、勾配計算Falseにしてしまう\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. BertLayerモジュールの最後を勾配計算ありに変更\n",
        "for param in net.bert.encoder.layer[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. 識別器を勾配計算ありに変更\n",
        "for param in net.cls.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df6eeIryHCP4"
      },
      "source": [
        "# 最適化手法の設定\n",
        "import torch.optim as optim\n",
        "\n",
        "# BERTの元の部分はファインチューニング\n",
        "optimizer = optim.Adam([\n",
        "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
        "    {'params': net.cls.parameters(), 'lr': 1e-3}\n",
        "])\n",
        "\n",
        "# 損失関数\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsIQUI5xUs8D",
        "outputId": "58ec7f1c-4daf-4fa4-db19-606621665572"
      },
      "source": [
        "# -*- coding:utf-8 -*-\n",
        "import torch\n",
        "\n",
        "print(torch.__version__) # 0.4.0"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RkvsR3rnt4O"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "            iteration = 1\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch.Text[0].to(device)  # 文章\n",
        "                labels = batch.Label.to(device)  # ラベル\n",
        "                labels2 = batch.Label2.to(device)\n",
        "                labels3 = batch.Label3.to(device)\n",
        "                labels4 = batch.Label4.to(device)\n",
        "                labels5 = batch.Label5.to(device)\n",
        "                labels6 = batch.Label6.to(device)\n",
        "                labels7 = batch.Label7.to(device)\n",
        "                labels8 = batch.Label8.to(device)\n",
        "                labels9 = batch.Label9.to(device)\n",
        "                labels10 = batch.Label10.to(device)\n",
        "                labels11 = batch.Label11.to(device)\n",
        "                labels12 = batch.Label12.to(device)\n",
        "                pa = torch.stack([labels, labels2, labels3, labels4, labels5,labels6,labels7,labels8,labels9,labels10, labels11, labels12], dim = 1)\n",
        "                \n",
        "                pa = torch.tensor(pa, dtype=torch.float32)\n",
        "\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # BERTに入力\n",
        "                    outputs = net(inputs)\n",
        "##############################################################################################################################################\n",
        "\n",
        "\n",
        "                    loss = criterion(outputs, pa)  # 損失を計算\n",
        "\n",
        "#第二引数の1は行。axis = 1と同じ。\n",
        "#torch.maxは最大値（テンソル）とその要素位置の２つを返しますが、その最大値を_で受けとっています。　ただ、最大値は不要なので適当な名前(_)の変数としています。\n",
        "                    preds = 0\n",
        "                    preds = outputs\n",
        "                    m = nn.Softmax(dim=1)\n",
        "                    preds = m(preds)\n",
        "\n",
        "                    preds = torch.round(preds)\n",
        "                  \n",
        "\n",
        "\n",
        "                    # 訓練時は逆誤差伝搬\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "#10イテレーションごとの計算で、割るときの分母にはバッチサイズに12をかけておく\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            acc = (torch.sum(preds == pa.data)\n",
        "                                   ).double()/(12*batch_size)\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter. || 本イテレーションの正解率：{}'.format(\n",
        "                                iteration, loss.item(),  acc))\n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    # 損失と正解数の合計を更新\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == pa.data)                    \n",
        "\n",
        "            # epochごとのlossと正解率\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / (12*len(dataloaders_dict[phase].dataset))\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return net"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoMz9KGUHF95"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "            iteration = 1\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch.Text[0].to(device)  # 文章\n",
        "                labels = batch.Label.to(device)  # ラベル\n",
        "                labels2 = batch.Label2.to(device)\n",
        "                labels3 = batch.Label3.to(device)\n",
        "                labels4 = batch.Label4.to(device)\n",
        "                labels5 = batch.Label5.to(device)\n",
        "                labels6 = batch.Label6.to(device)\n",
        "                labels7 = batch.Label7.to(device)\n",
        "                labels8 = batch.Label8.to(device)\n",
        "                labels9 = batch.Label9.to(device)\n",
        "                labels10 = batch.Label10.to(device)\n",
        "                labels11 = batch.Label11.to(device)\n",
        "                labels12 = batch.Label12.to(device)\n",
        "                pa = torch.stack([labels, labels2, labels3, labels4, labels5,labels6,labels7,labels8,labels9,labels10, labels11, labels12], dim = 1)\n",
        "                \n",
        "                pa = torch.tensor(pa, dtype=torch.float32)\n",
        "\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # BERTに入力\n",
        "                    outputs = net(inputs)\n",
        "##############################################################################################################################################\n",
        "\n",
        "\n",
        "                    loss = criterion(outputs, pa)  # 損失を計算\n",
        "                    Loss = float(loss)\n",
        "                    print(\"Loss : \", Loss)\n",
        "    \n",
        "#第二引数の1は行。axis = 1と同じ。\n",
        "#torch.maxは最大値（テンソル）とその要素位置の２つを返しますが、その最大値を_で受けとっています。　ただ、最大値は不要なので適当な名前(_)の変数としています。\n",
        "\n",
        "                \n",
        "                    # 訓練時は逆誤差伝搬\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "#10イテレーションごとの計算で、割るときの分母にはバッチサイズに12をかけておく\n",
        "            print('Epoch :',epoch+1)\n",
        "\n",
        "    return net"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXSW6SrYujd3",
        "outputId": "5d8fdc25-780f-4e34-bb91-34ed0134a063"
      },
      "source": [
        "# 学習・検証を実行する。\n",
        "num_epochs = 20\n",
        "\n",
        "net_trained = train_model(net, dataloaders_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "-----start-------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss :  0.9969847202301025\n",
            "Loss :  0.7635351419448853\n",
            "Loss :  0.6139737367630005\n",
            "Loss :  0.5114029049873352\n",
            "Loss :  0.43656885623931885\n",
            "Loss :  0.43099236488342285\n",
            "Loss :  0.3724709749221802\n",
            "Loss :  0.32569804787635803\n",
            "Loss :  0.43477344512939453\n",
            "Loss :  0.4566986858844757\n",
            "Loss :  0.480097234249115\n",
            "Loss :  0.33428841829299927\n",
            "Loss :  0.5237143635749817\n",
            "Loss :  0.3894786834716797\n",
            "Loss :  0.360396146774292\n",
            "Loss :  0.3716301918029785\n",
            "Loss :  0.4408351182937622\n",
            "Loss :  0.520209789276123\n",
            "Loss :  0.45691490173339844\n",
            "Loss :  0.40028128027915955\n",
            "Loss :  0.45075878500938416\n",
            "Loss :  0.38010263442993164\n",
            "Loss :  0.33838731050491333\n",
            "Loss :  0.3762267529964447\n",
            "Loss :  0.35005417466163635\n",
            "Loss :  0.41747960448265076\n",
            "Loss :  0.40989676117897034\n",
            "Loss :  0.3556002080440521\n",
            "Loss :  0.30180516839027405\n",
            "Loss :  0.39061084389686584\n",
            "Loss :  0.42348718643188477\n",
            "Loss :  0.3920705318450928\n",
            "Loss :  0.46204376220703125\n",
            "Loss :  0.3898143172264099\n",
            "Loss :  0.3653140962123871\n",
            "Loss :  0.3296594023704529\n",
            "Loss :  0.3902586102485657\n",
            "Loss :  0.36447182297706604\n",
            "Loss :  0.3150162100791931\n",
            "Loss :  0.30187755823135376\n",
            "Loss :  0.4472831189632416\n",
            "Loss :  0.30226966738700867\n",
            "Loss :  0.3685036599636078\n",
            "Loss :  0.4463498890399933\n",
            "Loss :  0.3451334238052368\n",
            "Loss :  0.47951439023017883\n",
            "Loss :  0.34684187173843384\n",
            "Loss :  0.37044018507003784\n",
            "Loss :  0.5449140071868896\n",
            "Loss :  0.3761710226535797\n",
            "Loss :  0.36761632561683655\n",
            "Loss :  0.40431931614875793\n",
            "Loss :  0.33648815751075745\n",
            "Loss :  0.3405720293521881\n",
            "Loss :  0.3351001739501953\n",
            "Loss :  0.4243144094944\n",
            "Loss :  0.36801260709762573\n",
            "Loss :  0.30473145842552185\n",
            "Loss :  0.4037948250770569\n",
            "Loss :  0.3781156539916992\n",
            "Epoch : 1\n",
            "Loss :  0.34288278222084045\n",
            "Loss :  0.40915754437446594\n",
            "Loss :  0.383327841758728\n",
            "Loss :  0.2982078492641449\n",
            "Loss :  0.3426186144351959\n",
            "Loss :  0.37215086817741394\n",
            "Loss :  0.3821519911289215\n",
            "Loss :  0.33513298630714417\n",
            "Loss :  0.36808162927627563\n",
            "Loss :  0.4721493124961853\n",
            "Loss :  0.3360516130924225\n",
            "Loss :  0.35001346468925476\n",
            "Loss :  0.317327618598938\n",
            "Loss :  0.34519830346107483\n",
            "Loss :  0.44089600443840027\n",
            "Loss :  0.3792547583580017\n",
            "Loss :  0.3394358456134796\n",
            "Loss :  0.313422828912735\n",
            "Loss :  0.414531409740448\n",
            "Loss :  0.34549829363822937\n",
            "Epoch : 1\n",
            "Loss :  0.3499336242675781\n",
            "Loss :  0.45181432366371155\n",
            "Loss :  0.32555511593818665\n",
            "Loss :  0.3449016213417053\n",
            "Loss :  0.31004205346107483\n",
            "Loss :  0.3956725597381592\n",
            "Loss :  0.4390312731266022\n",
            "Loss :  0.3816407024860382\n",
            "Loss :  0.3180343806743622\n",
            "Loss :  0.4462161064147949\n",
            "Loss :  0.31506675481796265\n",
            "Loss :  0.4098960757255554\n",
            "Loss :  0.36126843094825745\n",
            "Loss :  0.43518364429473877\n",
            "Loss :  0.37571021914482117\n",
            "Loss :  0.3883224129676819\n",
            "Loss :  0.32889652252197266\n",
            "Loss :  0.277159184217453\n",
            "Loss :  0.37581667304039\n",
            "Loss :  0.2927709221839905\n",
            "Loss :  0.44930750131607056\n",
            "Loss :  0.3864124119281769\n",
            "Loss :  0.4002785384654999\n",
            "Loss :  0.32302770018577576\n",
            "Loss :  0.4317444860935211\n",
            "Loss :  0.3527992069721222\n",
            "Loss :  0.35049960017204285\n",
            "Loss :  0.3808315694332123\n",
            "Loss :  0.32503315806388855\n",
            "Loss :  0.28169092535972595\n",
            "Loss :  0.37083521485328674\n",
            "Loss :  0.32755908370018005\n",
            "Loss :  0.36887916922569275\n",
            "Loss :  0.3172054588794708\n",
            "Loss :  0.39058300852775574\n",
            "Loss :  0.33915209770202637\n",
            "Loss :  0.44530025124549866\n",
            "Loss :  0.33302798867225647\n",
            "Loss :  0.4294987916946411\n",
            "Loss :  0.44981417059898376\n",
            "Loss :  0.3543333113193512\n",
            "Loss :  0.2870875597000122\n",
            "Loss :  0.3987889885902405\n",
            "Loss :  0.37623363733291626\n",
            "Loss :  0.37470585107803345\n",
            "Loss :  0.35012730956077576\n",
            "Loss :  0.40926218032836914\n",
            "Loss :  0.41407591104507446\n",
            "Loss :  0.41690078377723694\n",
            "Loss :  0.37685835361480713\n",
            "Loss :  0.3577660024166107\n",
            "Loss :  0.4376692771911621\n",
            "Loss :  0.436333566904068\n",
            "Loss :  0.4048086702823639\n",
            "Loss :  0.31846410036087036\n",
            "Loss :  0.3696310818195343\n",
            "Loss :  0.335114061832428\n",
            "Loss :  0.3898179233074188\n",
            "Loss :  0.4268155097961426\n",
            "Loss :  0.45001697540283203\n",
            "Epoch : 2\n",
            "Loss :  0.34965553879737854\n",
            "Loss :  0.4025806188583374\n",
            "Loss :  0.40444889664649963\n",
            "Loss :  0.3125843405723572\n",
            "Loss :  0.350933700799942\n",
            "Loss :  0.3878222107887268\n",
            "Loss :  0.37835511565208435\n",
            "Loss :  0.3452724516391754\n",
            "Loss :  0.3489401340484619\n",
            "Loss :  0.4717070162296295\n",
            "Loss :  0.33932971954345703\n",
            "Loss :  0.34646403789520264\n",
            "Loss :  0.32002145051956177\n",
            "Loss :  0.3700035512447357\n",
            "Loss :  0.43960097432136536\n",
            "Loss :  0.39162397384643555\n",
            "Loss :  0.3230946958065033\n",
            "Loss :  0.31956353783607483\n",
            "Loss :  0.4023905098438263\n",
            "Loss :  0.3681485950946808\n",
            "Epoch : 2\n",
            "Loss :  0.3514561951160431\n",
            "Loss :  0.3604113757610321\n",
            "Loss :  0.34950312972068787\n",
            "Loss :  0.355844646692276\n",
            "Loss :  0.3446756601333618\n",
            "Loss :  0.30996230244636536\n",
            "Loss :  0.3027936518192291\n",
            "Loss :  0.46269142627716064\n",
            "Loss :  0.2744031250476837\n",
            "Loss :  0.4937020540237427\n",
            "Loss :  0.41218435764312744\n",
            "Loss :  0.4437071681022644\n",
            "Loss :  0.31840577721595764\n",
            "Loss :  0.3414931297302246\n",
            "Loss :  0.3032034933567047\n",
            "Loss :  0.3477727174758911\n",
            "Loss :  0.3304930329322815\n",
            "Loss :  0.3429357707500458\n",
            "Loss :  0.508699357509613\n",
            "Loss :  0.31450405716896057\n",
            "Loss :  0.28956910967826843\n",
            "Loss :  0.33110156655311584\n",
            "Loss :  0.39936891198158264\n",
            "Loss :  0.42411425709724426\n",
            "Loss :  0.44173017144203186\n",
            "Loss :  0.3581840991973877\n",
            "Loss :  0.34643736481666565\n",
            "Loss :  0.43802112340927124\n",
            "Loss :  0.4468161165714264\n",
            "Loss :  0.3201886713504791\n",
            "Loss :  0.5310717821121216\n",
            "Loss :  0.3174794614315033\n",
            "Loss :  0.4195880889892578\n",
            "Loss :  0.2934791147708893\n",
            "Loss :  0.4082745909690857\n",
            "Loss :  0.4125138819217682\n",
            "Loss :  0.3607007563114166\n",
            "Loss :  0.33501890301704407\n",
            "Loss :  0.3205704092979431\n",
            "Loss :  0.34916749596595764\n",
            "Loss :  0.3603241741657257\n",
            "Loss :  0.34288734197616577\n",
            "Loss :  0.3307778239250183\n",
            "Loss :  0.5022292733192444\n",
            "Loss :  0.2828459143638611\n",
            "Loss :  0.32639139890670776\n",
            "Loss :  0.43296194076538086\n",
            "Loss :  0.4047078490257263\n",
            "Loss :  0.4687022268772125\n",
            "Loss :  0.3169381320476532\n",
            "Loss :  0.4171467423439026\n",
            "Loss :  0.3492189943790436\n",
            "Loss :  0.42845913767814636\n",
            "Loss :  0.30233341455459595\n",
            "Loss :  0.38711071014404297\n",
            "Loss :  0.30241841077804565\n",
            "Loss :  0.4701685905456543\n",
            "Loss :  0.3348275423049927\n",
            "Loss :  0.37959328293800354\n",
            "Loss :  0.37892669439315796\n",
            "Epoch : 3\n",
            "Loss :  0.33461061120033264\n",
            "Loss :  0.3999561369419098\n",
            "Loss :  0.4071517586708069\n",
            "Loss :  0.2888045907020569\n",
            "Loss :  0.32980045676231384\n",
            "Loss :  0.3816232979297638\n",
            "Loss :  0.38200655579566956\n",
            "Loss :  0.3395419716835022\n",
            "Loss :  0.33252209424972534\n",
            "Loss :  0.46722322702407837\n",
            "Loss :  0.3163256049156189\n",
            "Loss :  0.3470790386199951\n",
            "Loss :  0.31208062171936035\n",
            "Loss :  0.3685981035232544\n",
            "Loss :  0.44255542755126953\n",
            "Loss :  0.3823414444923401\n",
            "Loss :  0.34969592094421387\n",
            "Loss :  0.35155603289604187\n",
            "Loss :  0.4094667136669159\n",
            "Loss :  0.3530891239643097\n",
            "Epoch : 3\n",
            "Loss :  0.402974933385849\n",
            "Loss :  0.45718246698379517\n",
            "Loss :  0.4209079146385193\n",
            "Loss :  0.44307103753089905\n",
            "Loss :  0.3693503439426422\n",
            "Loss :  0.37201783061027527\n",
            "Loss :  0.37747976183891296\n",
            "Loss :  0.334649920463562\n",
            "Loss :  0.4439532458782196\n",
            "Loss :  0.3282288610935211\n",
            "Loss :  0.3723955452442169\n",
            "Loss :  0.32695841789245605\n",
            "Loss :  0.30878666043281555\n",
            "Loss :  0.42745593190193176\n",
            "Loss :  0.35784733295440674\n",
            "Loss :  0.3212031424045563\n",
            "Loss :  0.34776854515075684\n",
            "Loss :  0.36242935061454773\n",
            "Loss :  0.3474608063697815\n",
            "Loss :  0.3681146204471588\n",
            "Loss :  0.4490836560726166\n",
            "Loss :  0.39813777804374695\n",
            "Loss :  0.38228583335876465\n",
            "Loss :  0.35017693042755127\n",
            "Loss :  0.4509739279747009\n",
            "Loss :  0.3484872281551361\n",
            "Loss :  0.35171741247177124\n",
            "Loss :  0.36162832379341125\n",
            "Loss :  0.46998539566993713\n",
            "Loss :  0.4449142813682556\n",
            "Loss :  0.37401941418647766\n",
            "Loss :  0.3129675090312958\n",
            "Loss :  0.4482211172580719\n",
            "Loss :  0.39345085620880127\n",
            "Loss :  0.33415427803993225\n",
            "Loss :  0.4048589766025543\n",
            "Loss :  0.344787061214447\n",
            "Loss :  0.35941755771636963\n",
            "Loss :  0.38012218475341797\n",
            "Loss :  0.3161003291606903\n",
            "Loss :  0.3386325240135193\n",
            "Loss :  0.39126503467559814\n",
            "Loss :  0.30116409063339233\n",
            "Loss :  0.34782108664512634\n",
            "Loss :  0.3206915557384491\n",
            "Loss :  0.3833819031715393\n",
            "Loss :  0.48316362500190735\n",
            "Loss :  0.33029088377952576\n",
            "Loss :  0.4516535997390747\n",
            "Loss :  0.3497697412967682\n",
            "Loss :  0.3501681387424469\n",
            "Loss :  0.34573036432266235\n",
            "Loss :  0.37673935294151306\n",
            "Loss :  0.28046008944511414\n",
            "Loss :  0.46031537652015686\n",
            "Loss :  0.3294781446456909\n",
            "Loss :  0.380238801240921\n",
            "Loss :  0.35089290142059326\n",
            "Loss :  0.28579822182655334\n",
            "Loss :  0.36675968766212463\n",
            "Epoch : 4\n",
            "Loss :  0.3417622148990631\n",
            "Loss :  0.4069034457206726\n",
            "Loss :  0.40695181488990784\n",
            "Loss :  0.28318658471107483\n",
            "Loss :  0.35045164823532104\n",
            "Loss :  0.37880468368530273\n",
            "Loss :  0.37335771322250366\n",
            "Loss :  0.34600767493247986\n",
            "Loss :  0.34973061084747314\n",
            "Loss :  0.4874831736087799\n",
            "Loss :  0.34441158175468445\n",
            "Loss :  0.35080644488334656\n",
            "Loss :  0.3266162872314453\n",
            "Loss :  0.3577660024166107\n",
            "Loss :  0.43619534373283386\n",
            "Loss :  0.3732423186302185\n",
            "Loss :  0.32837167382240295\n",
            "Loss :  0.33256202936172485\n",
            "Loss :  0.39519888162612915\n",
            "Loss :  0.3414316773414612\n",
            "Epoch : 4\n",
            "Loss :  0.35337892174720764\n",
            "Loss :  0.3842516243457794\n",
            "Loss :  0.35101377964019775\n",
            "Loss :  0.37012043595314026\n",
            "Loss :  0.2986510396003723\n",
            "Loss :  0.4148038625717163\n",
            "Loss :  0.44213810563087463\n",
            "Loss :  0.3949315845966339\n",
            "Loss :  0.37319281697273254\n",
            "Loss :  0.42581647634506226\n",
            "Loss :  0.4681481420993805\n",
            "Loss :  0.38170352578163147\n",
            "Loss :  0.34762221574783325\n",
            "Loss :  0.48798269033432007\n",
            "Loss :  0.34433290362358093\n",
            "Loss :  0.43805405497550964\n",
            "Loss :  0.43655866384506226\n",
            "Loss :  0.36248818039894104\n",
            "Loss :  0.3395446240901947\n",
            "Loss :  0.45392894744873047\n",
            "Loss :  0.35877031087875366\n",
            "Loss :  0.3795877695083618\n",
            "Loss :  0.42002642154693604\n",
            "Loss :  0.35766276717185974\n",
            "Loss :  0.35061803460121155\n",
            "Loss :  0.38222646713256836\n",
            "Loss :  0.37449097633361816\n",
            "Loss :  0.3407139480113983\n",
            "Loss :  0.3642277121543884\n",
            "Loss :  0.3816680908203125\n",
            "Loss :  0.4115528464317322\n",
            "Loss :  0.42935842275619507\n",
            "Loss :  0.4224945306777954\n",
            "Loss :  0.2747522294521332\n",
            "Loss :  0.3793974220752716\n",
            "Loss :  0.30592358112335205\n",
            "Loss :  0.30986398458480835\n",
            "Loss :  0.405057817697525\n",
            "Loss :  0.31980377435684204\n",
            "Loss :  0.33974143862724304\n",
            "Loss :  0.45278555154800415\n",
            "Loss :  0.3419717848300934\n",
            "Loss :  0.3956092596054077\n",
            "Loss :  0.3052450120449066\n",
            "Loss :  0.3738023340702057\n",
            "Loss :  0.33633413910865784\n",
            "Loss :  0.30179452896118164\n",
            "Loss :  0.31128376722335815\n",
            "Loss :  0.3002283275127411\n",
            "Loss :  0.3961000442504883\n",
            "Loss :  0.4052981734275818\n",
            "Loss :  0.41402384638786316\n",
            "Loss :  0.40825366973876953\n",
            "Loss :  0.28265124559402466\n",
            "Loss :  0.32090023159980774\n",
            "Loss :  0.42009294033050537\n",
            "Loss :  0.39516791701316833\n",
            "Loss :  0.3482191860675812\n",
            "Loss :  0.3525736927986145\n",
            "Loss :  0.33483901619911194\n",
            "Epoch : 5\n",
            "Loss :  0.3425986170768738\n",
            "Loss :  0.4013028144836426\n",
            "Loss :  0.401569128036499\n",
            "Loss :  0.28736311197280884\n",
            "Loss :  0.3461618423461914\n",
            "Loss :  0.3613228499889374\n",
            "Loss :  0.3533494174480438\n",
            "Loss :  0.34038078784942627\n",
            "Loss :  0.34224095940589905\n",
            "Loss :  0.4721302390098572\n",
            "Loss :  0.33262771368026733\n",
            "Loss :  0.34460821747779846\n",
            "Loss :  0.3212900757789612\n",
            "Loss :  0.35445743799209595\n",
            "Loss :  0.43664073944091797\n",
            "Loss :  0.36545220017433167\n",
            "Loss :  0.32031285762786865\n",
            "Loss :  0.3277193307876587\n",
            "Loss :  0.3915856182575226\n",
            "Loss :  0.33966270089149475\n",
            "Epoch : 5\n",
            "Loss :  0.4817083179950714\n",
            "Loss :  0.38809600472450256\n",
            "Loss :  0.4117411673069\n",
            "Loss :  0.36948537826538086\n",
            "Loss :  0.3002128601074219\n",
            "Loss :  0.4027497172355652\n",
            "Loss :  0.3540612757205963\n",
            "Loss :  0.3443745970726013\n",
            "Loss :  0.32309690117836\n",
            "Loss :  0.3315398693084717\n",
            "Loss :  0.31678295135498047\n",
            "Loss :  0.4056052267551422\n",
            "Loss :  0.47606679797172546\n",
            "Loss :  0.38698291778564453\n",
            "Loss :  0.4055537283420563\n",
            "Loss :  0.35730400681495667\n",
            "Loss :  0.34182390570640564\n",
            "Loss :  0.33574458956718445\n",
            "Loss :  0.4382683038711548\n",
            "Loss :  0.35691210627555847\n",
            "Loss :  0.28737789392471313\n",
            "Loss :  0.43995344638824463\n",
            "Loss :  0.3438006341457367\n",
            "Loss :  0.30896514654159546\n",
            "Loss :  0.37522029876708984\n",
            "Loss :  0.3560948669910431\n",
            "Loss :  0.4083845317363739\n",
            "Loss :  0.3643050491809845\n",
            "Loss :  0.39527007937431335\n",
            "Loss :  0.3442052900791168\n",
            "Loss :  0.4063459038734436\n",
            "Loss :  0.4133223593235016\n",
            "Loss :  0.365326464176178\n",
            "Loss :  0.30491748452186584\n",
            "Loss :  0.36244675517082214\n",
            "Loss :  0.45227617025375366\n",
            "Loss :  0.3769034147262573\n",
            "Loss :  0.44067123532295227\n",
            "Loss :  0.3193010091781616\n",
            "Loss :  0.3613414764404297\n",
            "Loss :  0.3528776168823242\n",
            "Loss :  0.36413684487342834\n",
            "Loss :  0.33392924070358276\n",
            "Loss :  0.37012162804603577\n",
            "Loss :  0.31366539001464844\n",
            "Loss :  0.3690582513809204\n",
            "Loss :  0.5270687937736511\n",
            "Loss :  0.3171733319759369\n",
            "Loss :  0.43408265709877014\n",
            "Loss :  0.37770944833755493\n",
            "Loss :  0.3284943699836731\n",
            "Loss :  0.4036138951778412\n",
            "Loss :  0.3754502236843109\n",
            "Loss :  0.4052007496356964\n",
            "Loss :  0.3293238580226898\n",
            "Loss :  0.3131850063800812\n",
            "Loss :  0.36505281925201416\n",
            "Loss :  0.3089762330055237\n",
            "Loss :  0.33472883701324463\n",
            "Loss :  0.32701271772384644\n",
            "Epoch : 6\n",
            "Loss :  0.32994285225868225\n",
            "Loss :  0.4108411371707916\n",
            "Loss :  0.41843265295028687\n",
            "Loss :  0.295631468296051\n",
            "Loss :  0.3530023396015167\n",
            "Loss :  0.3791966736316681\n",
            "Loss :  0.36160558462142944\n",
            "Loss :  0.34094616770744324\n",
            "Loss :  0.33362796902656555\n",
            "Loss :  0.4675638973712921\n",
            "Loss :  0.3042253255844116\n",
            "Loss :  0.3254815638065338\n",
            "Loss :  0.3213023543357849\n",
            "Loss :  0.38117921352386475\n",
            "Loss :  0.4302726984024048\n",
            "Loss :  0.37016117572784424\n",
            "Loss :  0.30554261803627014\n",
            "Loss :  0.31807851791381836\n",
            "Loss :  0.39391615986824036\n",
            "Loss :  0.34574955701828003\n",
            "Epoch : 6\n",
            "Loss :  0.37675783038139343\n",
            "Loss :  0.353080689907074\n",
            "Loss :  0.37692147493362427\n",
            "Loss :  0.360294371843338\n",
            "Loss :  0.3445720076560974\n",
            "Loss :  0.37411749362945557\n",
            "Loss :  0.46647337079048157\n",
            "Loss :  0.3211873471736908\n",
            "Loss :  0.3584747612476349\n",
            "Loss :  0.33100754022598267\n",
            "Loss :  0.5504949688911438\n",
            "Loss :  0.2991880476474762\n",
            "Loss :  0.36828798055648804\n",
            "Loss :  0.336588591337204\n",
            "Loss :  0.34414923191070557\n",
            "Loss :  0.3935681879520416\n",
            "Loss :  0.35340356826782227\n",
            "Loss :  0.32453250885009766\n",
            "Loss :  0.37596744298934937\n",
            "Loss :  0.35957804322242737\n",
            "Loss :  0.30447617173194885\n",
            "Loss :  0.4387122690677643\n",
            "Loss :  0.3244117796421051\n",
            "Loss :  0.39719220995903015\n",
            "Loss :  0.28688547015190125\n",
            "Loss :  0.3314964473247528\n",
            "Loss :  0.35035377740859985\n",
            "Loss :  0.3796112835407257\n",
            "Loss :  0.3472142815589905\n",
            "Loss :  0.3517531454563141\n",
            "Loss :  0.36830317974090576\n",
            "Loss :  0.35647234320640564\n",
            "Loss :  0.4677353501319885\n",
            "Loss :  0.3152739107608795\n",
            "Loss :  0.3600366711616516\n",
            "Loss :  0.46658816933631897\n",
            "Loss :  0.41215306520462036\n",
            "Loss :  0.33554890751838684\n",
            "Loss :  0.31869545578956604\n",
            "Loss :  0.32557412981987\n",
            "Loss :  0.4109252691268921\n",
            "Loss :  0.330863893032074\n",
            "Loss :  0.3950809836387634\n",
            "Loss :  0.5012855529785156\n",
            "Loss :  0.3246411383152008\n",
            "Loss :  0.3628714978694916\n",
            "Loss :  0.2863024175167084\n",
            "Loss :  0.40802234411239624\n",
            "Loss :  0.3444693684577942\n",
            "Loss :  0.27540484070777893\n",
            "Loss :  0.3030685484409332\n",
            "Loss :  0.35646823048591614\n",
            "Loss :  0.3390451967716217\n",
            "Loss :  0.32355454564094543\n",
            "Loss :  0.3379115164279938\n",
            "Loss :  0.3479245603084564\n",
            "Loss :  0.5571768879890442\n",
            "Loss :  0.30492687225341797\n",
            "Loss :  0.38611355423927307\n",
            "Loss :  0.4931427538394928\n",
            "Epoch : 7\n",
            "Loss :  0.3400435745716095\n",
            "Loss :  0.37821638584136963\n",
            "Loss :  0.41552767157554626\n",
            "Loss :  0.2731281518936157\n",
            "Loss :  0.3366907238960266\n",
            "Loss :  0.3418380320072174\n",
            "Loss :  0.34305626153945923\n",
            "Loss :  0.3195106089115143\n",
            "Loss :  0.3216407895088196\n",
            "Loss :  0.4579083025455475\n",
            "Loss :  0.3137587010860443\n",
            "Loss :  0.31601381301879883\n",
            "Loss :  0.3065114915370941\n",
            "Loss :  0.3603500425815582\n",
            "Loss :  0.42384111881256104\n",
            "Loss :  0.3617808520793915\n",
            "Loss :  0.29690325260162354\n",
            "Loss :  0.30981048941612244\n",
            "Loss :  0.3957204222679138\n",
            "Loss :  0.33560335636138916\n",
            "Epoch : 7\n",
            "Loss :  0.40695613622665405\n",
            "Loss :  0.3561882972717285\n",
            "Loss :  0.3402673304080963\n",
            "Loss :  0.3411042392253876\n",
            "Loss :  0.31978803873062134\n",
            "Loss :  0.361144095659256\n",
            "Loss :  0.34944993257522583\n",
            "Loss :  0.3305029273033142\n",
            "Loss :  0.30542314052581787\n",
            "Loss :  0.3505478799343109\n",
            "Loss :  0.38426414132118225\n",
            "Loss :  0.26675882935523987\n",
            "Loss :  0.36704206466674805\n",
            "Loss :  0.29298126697540283\n",
            "Loss :  0.3410910367965698\n",
            "Loss :  0.34661033749580383\n",
            "Loss :  0.29678791761398315\n",
            "Loss :  0.2639739215373993\n",
            "Loss :  0.29885897040367126\n",
            "Loss :  0.3038504421710968\n",
            "Loss :  0.4781854450702667\n",
            "Loss :  0.3971421420574188\n",
            "Loss :  0.3693920075893402\n",
            "Loss :  0.3020741045475006\n",
            "Loss :  0.35572320222854614\n",
            "Loss :  0.3803374469280243\n",
            "Loss :  0.3609980046749115\n",
            "Loss :  0.38687968254089355\n",
            "Loss :  0.3218902349472046\n",
            "Loss :  0.4001828730106354\n",
            "Loss :  0.2790175676345825\n",
            "Loss :  0.2611224055290222\n",
            "Loss :  0.3564884662628174\n",
            "Loss :  0.3320868909358978\n",
            "Loss :  0.2558014392852783\n",
            "Loss :  0.4010324478149414\n",
            "Loss :  0.306806743144989\n",
            "Loss :  0.3370583951473236\n",
            "Loss :  0.33316370844841003\n",
            "Loss :  0.3538065552711487\n",
            "Loss :  0.37805190682411194\n",
            "Loss :  0.3266567289829254\n",
            "Loss :  0.3126319944858551\n",
            "Loss :  0.3265591859817505\n",
            "Loss :  0.36557045578956604\n",
            "Loss :  0.4775518774986267\n",
            "Loss :  0.28379103541374207\n",
            "Loss :  0.393130898475647\n",
            "Loss :  0.3613925576210022\n",
            "Loss :  0.7155749201774597\n",
            "Loss :  0.30059996247291565\n",
            "Loss :  0.33910754323005676\n",
            "Loss :  0.3619536757469177\n",
            "Loss :  0.3112836480140686\n",
            "Loss :  0.2741835415363312\n",
            "Loss :  0.48718559741973877\n",
            "Loss :  0.4212718605995178\n",
            "Loss :  0.38118037581443787\n",
            "Loss :  0.5853300094604492\n",
            "Loss :  0.29957082867622375\n",
            "Epoch : 8\n",
            "Loss :  0.3338429033756256\n",
            "Loss :  0.3542829751968384\n",
            "Loss :  0.40871959924697876\n",
            "Loss :  0.25532469153404236\n",
            "Loss :  0.3397771120071411\n",
            "Loss :  0.3277702033519745\n",
            "Loss :  0.3449844419956207\n",
            "Loss :  0.30176469683647156\n",
            "Loss :  0.31121355295181274\n",
            "Loss :  0.4421510100364685\n",
            "Loss :  0.29825058579444885\n",
            "Loss :  0.2984887957572937\n",
            "Loss :  0.29460158944129944\n",
            "Loss :  0.3466006815433502\n",
            "Loss :  0.4114078879356384\n",
            "Loss :  0.34540972113609314\n",
            "Loss :  0.27854859828948975\n",
            "Loss :  0.2937232553958893\n",
            "Loss :  0.3692759573459625\n",
            "Loss :  0.3189969062805176\n",
            "Epoch : 8\n",
            "Loss :  0.27306318283081055\n",
            "Loss :  0.34995657205581665\n",
            "Loss :  0.3431483805179596\n",
            "Loss :  0.30465057492256165\n",
            "Loss :  0.31573402881622314\n",
            "Loss :  0.3585905432701111\n",
            "Loss :  0.4239306151866913\n",
            "Loss :  0.35197514295578003\n",
            "Loss :  0.37461355328559875\n",
            "Loss :  0.29468363523483276\n",
            "Loss :  0.3193605840206146\n",
            "Loss :  0.3547441363334656\n",
            "Loss :  0.37119007110595703\n",
            "Loss :  0.31012463569641113\n",
            "Loss :  0.354407399892807\n",
            "Loss :  0.3313140869140625\n",
            "Loss :  0.34263888001441956\n",
            "Loss :  0.40218058228492737\n",
            "Loss :  0.3595106601715088\n",
            "Loss :  0.26884403824806213\n",
            "Loss :  0.4763905107975006\n",
            "Loss :  0.41808584332466125\n",
            "Loss :  0.37483587861061096\n",
            "Loss :  0.3017118275165558\n",
            "Loss :  0.2699640095233917\n",
            "Loss :  0.394052118062973\n",
            "Loss :  0.2860233783721924\n",
            "Loss :  0.27011045813560486\n",
            "Loss :  0.3890639841556549\n",
            "Loss :  0.3481486737728119\n",
            "Loss :  0.2878333628177643\n",
            "Loss :  0.30736228823661804\n",
            "Loss :  0.3729890286922455\n",
            "Loss :  0.27457180619239807\n",
            "Loss :  0.29346951842308044\n",
            "Loss :  0.3437456488609314\n",
            "Loss :  0.2920648455619812\n",
            "Loss :  0.41949671506881714\n",
            "Loss :  0.36006590723991394\n",
            "Loss :  0.4018305838108063\n",
            "Loss :  0.31450819969177246\n",
            "Loss :  0.43181246519088745\n",
            "Loss :  0.3253612220287323\n",
            "Loss :  0.3612227141857147\n",
            "Loss :  0.2967178523540497\n",
            "Loss :  0.3032464385032654\n",
            "Loss :  0.47093692421913147\n",
            "Loss :  0.32081905007362366\n",
            "Loss :  0.2793332040309906\n",
            "Loss :  0.40425094962120056\n",
            "Loss :  0.3216087520122528\n",
            "Loss :  0.3388381600379944\n",
            "Loss :  0.32261452078819275\n",
            "Loss :  0.2879708409309387\n",
            "Loss :  0.26252350211143494\n",
            "Loss :  0.39523404836654663\n",
            "Loss :  0.3841051161289215\n",
            "Loss :  0.42826762795448303\n",
            "Loss :  0.307958722114563\n",
            "Loss :  0.27595245838165283\n",
            "Epoch : 9\n",
            "Loss :  0.33811190724372864\n",
            "Loss :  0.36570030450820923\n",
            "Loss :  0.4218267500400543\n",
            "Loss :  0.23762303590774536\n",
            "Loss :  0.33758845925331116\n",
            "Loss :  0.33787959814071655\n",
            "Loss :  0.3184460997581482\n",
            "Loss :  0.28988900780677795\n",
            "Loss :  0.2557200789451599\n",
            "Loss :  0.47354042530059814\n",
            "Loss :  0.2633591294288635\n",
            "Loss :  0.2919900715351105\n",
            "Loss :  0.27519723773002625\n",
            "Loss :  0.36781027913093567\n",
            "Loss :  0.4393599033355713\n",
            "Loss :  0.327006459236145\n",
            "Loss :  0.23963753879070282\n",
            "Loss :  0.2846183776855469\n",
            "Loss :  0.3535683751106262\n",
            "Loss :  0.32826972007751465\n",
            "Epoch : 9\n",
            "Loss :  0.3445410430431366\n",
            "Loss :  0.4299677908420563\n",
            "Loss :  0.3546725809574127\n",
            "Loss :  0.3055511713027954\n",
            "Loss :  0.44049492478370667\n",
            "Loss :  0.35417768359184265\n",
            "Loss :  0.33657145500183105\n",
            "Loss :  0.2921578586101532\n",
            "Loss :  0.45170846581459045\n",
            "Loss :  0.3860284090042114\n",
            "Loss :  0.31663864850997925\n",
            "Loss :  0.3285256624221802\n",
            "Loss :  0.4356127381324768\n",
            "Loss :  0.31850284337997437\n",
            "Loss :  0.3517859876155853\n",
            "Loss :  0.2715124189853668\n",
            "Loss :  0.37787100672721863\n",
            "Loss :  0.3139629065990448\n",
            "Loss :  0.29969534277915955\n",
            "Loss :  0.28519687056541443\n",
            "Loss :  0.34326115250587463\n",
            "Loss :  0.2910727262496948\n",
            "Loss :  0.31041887402534485\n",
            "Loss :  0.4960729777812958\n",
            "Loss :  0.3287668228149414\n",
            "Loss :  0.29749956727027893\n",
            "Loss :  0.25282156467437744\n",
            "Loss :  0.25034651160240173\n",
            "Loss :  0.31090036034584045\n",
            "Loss :  0.3142610192298889\n",
            "Loss :  0.27119961380958557\n",
            "Loss :  0.3523099720478058\n",
            "Loss :  0.3608241379261017\n",
            "Loss :  0.2594189941883087\n",
            "Loss :  0.35211020708084106\n",
            "Loss :  0.27946946024894714\n",
            "Loss :  0.4266057312488556\n",
            "Loss :  0.2506495714187622\n",
            "Loss :  0.3585177958011627\n",
            "Loss :  0.2968980073928833\n",
            "Loss :  0.2760295867919922\n",
            "Loss :  0.37672367691993713\n",
            "Loss :  0.3761771023273468\n",
            "Loss :  0.3023126721382141\n",
            "Loss :  0.2863016724586487\n",
            "Loss :  0.3031633794307709\n",
            "Loss :  0.29476800560951233\n",
            "Loss :  0.27209436893463135\n",
            "Loss :  0.45573514699935913\n",
            "Loss :  0.3444642126560211\n",
            "Loss :  0.5109879374504089\n",
            "Loss :  0.27975425124168396\n",
            "Loss :  0.4023880064487457\n",
            "Loss :  0.30337822437286377\n",
            "Loss :  0.2987440526485443\n",
            "Loss :  0.2968555986881256\n",
            "Loss :  0.32032591104507446\n",
            "Loss :  0.2716984748840332\n",
            "Loss :  0.26539766788482666\n",
            "Loss :  0.3175869286060333\n",
            "Epoch : 10\n",
            "Loss :  0.32466188073158264\n",
            "Loss :  0.32234707474708557\n",
            "Loss :  0.38131365180015564\n",
            "Loss :  0.24982015788555145\n",
            "Loss :  0.2916082441806793\n",
            "Loss :  0.3075677454471588\n",
            "Loss :  0.31558868288993835\n",
            "Loss :  0.2830983102321625\n",
            "Loss :  0.2794831693172455\n",
            "Loss :  0.46146631240844727\n",
            "Loss :  0.26576635241508484\n",
            "Loss :  0.29580384492874146\n",
            "Loss :  0.2583664357662201\n",
            "Loss :  0.32797467708587646\n",
            "Loss :  0.42585551738739014\n",
            "Loss :  0.3595425486564636\n",
            "Loss :  0.22162865102291107\n",
            "Loss :  0.2599249482154846\n",
            "Loss :  0.34089016914367676\n",
            "Loss :  0.3445882201194763\n",
            "Epoch : 10\n",
            "Loss :  0.22454261779785156\n",
            "Loss :  0.23046183586120605\n",
            "Loss :  0.3040338158607483\n",
            "Loss :  0.3190758526325226\n",
            "Loss :  0.3084235191345215\n",
            "Loss :  0.2396964579820633\n",
            "Loss :  0.3999307453632355\n",
            "Loss :  0.2660342752933502\n",
            "Loss :  0.3140961527824402\n",
            "Loss :  0.3394007980823517\n",
            "Loss :  0.4152047336101532\n",
            "Loss :  0.26532888412475586\n",
            "Loss :  0.42907440662384033\n",
            "Loss :  0.3017132878303528\n",
            "Loss :  0.3565686047077179\n",
            "Loss :  0.3078961968421936\n",
            "Loss :  0.3141952157020569\n",
            "Loss :  0.3111921548843384\n",
            "Loss :  0.3319546580314636\n",
            "Loss :  0.21652519702911377\n",
            "Loss :  0.3906848728656769\n",
            "Loss :  0.49191418290138245\n",
            "Loss :  0.27011406421661377\n",
            "Loss :  0.373839795589447\n",
            "Loss :  0.2704290449619293\n",
            "Loss :  0.26451390981674194\n",
            "Loss :  0.3617915213108063\n",
            "Loss :  0.24220368266105652\n",
            "Loss :  0.36788463592529297\n",
            "Loss :  0.2694943845272064\n",
            "Loss :  0.30524131655693054\n",
            "Loss :  0.37631070613861084\n",
            "Loss :  0.37442511320114136\n",
            "Loss :  0.22975297272205353\n",
            "Loss :  0.3910585939884186\n",
            "Loss :  0.3139740824699402\n",
            "Loss :  0.36353451013565063\n",
            "Loss :  0.3174881041049957\n",
            "Loss :  0.37220022082328796\n",
            "Loss :  0.26324358582496643\n",
            "Loss :  0.45720353722572327\n",
            "Loss :  0.23035208880901337\n",
            "Loss :  0.2946547567844391\n",
            "Loss :  0.34543076157569885\n",
            "Loss :  0.40659645199775696\n",
            "Loss :  0.23881298303604126\n",
            "Loss :  0.241195410490036\n",
            "Loss :  0.3104311525821686\n",
            "Loss :  0.240469828248024\n",
            "Loss :  0.2530354857444763\n",
            "Loss :  0.3271409869194031\n",
            "Loss :  0.23562775552272797\n",
            "Loss :  0.28245657682418823\n",
            "Loss :  0.3799801468849182\n",
            "Loss :  0.2790044844150543\n",
            "Loss :  0.37814944982528687\n",
            "Loss :  0.3001929521560669\n",
            "Loss :  0.32350262999534607\n",
            "Loss :  0.34699758887290955\n",
            "Loss :  0.2987695336341858\n",
            "Epoch : 11\n",
            "Loss :  0.3282313942909241\n",
            "Loss :  0.34597650170326233\n",
            "Loss :  0.40690070390701294\n",
            "Loss :  0.25404804944992065\n",
            "Loss :  0.2958846092224121\n",
            "Loss :  0.32250311970710754\n",
            "Loss :  0.3095674216747284\n",
            "Loss :  0.2942732870578766\n",
            "Loss :  0.25491195917129517\n",
            "Loss :  0.48336729407310486\n",
            "Loss :  0.25218746066093445\n",
            "Loss :  0.2710816562175751\n",
            "Loss :  0.26735740900039673\n",
            "Loss :  0.34428584575653076\n",
            "Loss :  0.43230634927749634\n",
            "Loss :  0.34668177366256714\n",
            "Loss :  0.20584586262702942\n",
            "Loss :  0.27080652117729187\n",
            "Loss :  0.3554271459579468\n",
            "Loss :  0.354360967874527\n",
            "Epoch : 11\n",
            "Loss :  0.3728982210159302\n",
            "Loss :  0.2580498158931732\n",
            "Loss :  0.3133538067340851\n",
            "Loss :  0.28142812848091125\n",
            "Loss :  0.27008822560310364\n",
            "Loss :  0.3552800416946411\n",
            "Loss :  0.30909463763237\n",
            "Loss :  0.24278821051120758\n",
            "Loss :  0.23489899933338165\n",
            "Loss :  0.3004336953163147\n",
            "Loss :  0.38011735677719116\n",
            "Loss :  0.358081191778183\n",
            "Loss :  0.2972675859928131\n",
            "Loss :  0.27995243668556213\n",
            "Loss :  0.30256134271621704\n",
            "Loss :  0.2539710998535156\n",
            "Loss :  0.34330135583877563\n",
            "Loss :  0.30531713366508484\n",
            "Loss :  0.2688845098018646\n",
            "Loss :  0.2428363412618637\n",
            "Loss :  0.30280181765556335\n",
            "Loss :  0.33377256989479065\n",
            "Loss :  0.33100682497024536\n",
            "Loss :  0.25549158453941345\n",
            "Loss :  0.2827290892601013\n",
            "Loss :  0.2865177392959595\n",
            "Loss :  0.2481069564819336\n",
            "Loss :  0.3465854823589325\n",
            "Loss :  0.3464253544807434\n",
            "Loss :  0.2491132915019989\n",
            "Loss :  0.29618173837661743\n",
            "Loss :  0.40878766775131226\n",
            "Loss :  0.2853552997112274\n",
            "Loss :  0.4378690719604492\n",
            "Loss :  0.2729220986366272\n",
            "Loss :  0.38580384850502014\n",
            "Loss :  0.3352276086807251\n",
            "Loss :  0.2648122310638428\n",
            "Loss :  0.29600822925567627\n",
            "Loss :  0.25305789709091187\n",
            "Loss :  0.24922983348369598\n",
            "Loss :  0.44910043478012085\n",
            "Loss :  0.29027384519577026\n",
            "Loss :  0.2430751621723175\n",
            "Loss :  0.25033241510391235\n",
            "Loss :  0.2927173972129822\n",
            "Loss :  0.28499579429626465\n",
            "Loss :  0.2785300016403198\n",
            "Loss :  0.2695350646972656\n",
            "Loss :  0.36952459812164307\n",
            "Loss :  0.3216640055179596\n",
            "Loss :  0.3157517910003662\n",
            "Loss :  0.28452712297439575\n",
            "Loss :  0.2490236461162567\n",
            "Loss :  0.3196166753768921\n",
            "Loss :  0.29589807987213135\n",
            "Loss :  0.25796499848365784\n",
            "Loss :  0.4844296872615814\n",
            "Loss :  0.25123468041419983\n",
            "Loss :  0.33224454522132874\n",
            "Epoch : 12\n",
            "Loss :  0.32292303442955017\n",
            "Loss :  0.3129442036151886\n",
            "Loss :  0.37796923518180847\n",
            "Loss :  0.24449412524700165\n",
            "Loss :  0.26945388317108154\n",
            "Loss :  0.3110910952091217\n",
            "Loss :  0.3465852737426758\n",
            "Loss :  0.29184648394584656\n",
            "Loss :  0.2631131708621979\n",
            "Loss :  0.46674251556396484\n",
            "Loss :  0.2506622076034546\n",
            "Loss :  0.30985456705093384\n",
            "Loss :  0.27374130487442017\n",
            "Loss :  0.32153454422950745\n",
            "Loss :  0.3916794955730438\n",
            "Loss :  0.3520927429199219\n",
            "Loss :  0.21328063309192657\n",
            "Loss :  0.24766744673252106\n",
            "Loss :  0.343371719121933\n",
            "Loss :  0.3362177908420563\n",
            "Epoch : 12\n",
            "Loss :  0.2745203971862793\n",
            "Loss :  0.2458372712135315\n",
            "Loss :  0.2593860328197479\n",
            "Loss :  0.2609034776687622\n",
            "Loss :  0.24795866012573242\n",
            "Loss :  0.3150852918624878\n",
            "Loss :  0.2730756103992462\n",
            "Loss :  0.2351999580860138\n",
            "Loss :  0.3260304033756256\n",
            "Loss :  0.3558848202228546\n",
            "Loss :  0.275526225566864\n",
            "Loss :  0.40530717372894287\n",
            "Loss :  0.24956396222114563\n",
            "Loss :  0.2626661956310272\n",
            "Loss :  0.27176809310913086\n",
            "Loss :  0.29183429479599\n",
            "Loss :  0.362790048122406\n",
            "Loss :  0.33151617646217346\n",
            "Loss :  0.20675593614578247\n",
            "Loss :  0.3313564360141754\n",
            "Loss :  0.30263274908065796\n",
            "Loss :  0.2468712031841278\n",
            "Loss :  0.2356203943490982\n",
            "Loss :  0.32225194573402405\n",
            "Loss :  0.3335312306880951\n",
            "Loss :  0.34051671624183655\n",
            "Loss :  0.26181474328041077\n",
            "Loss :  0.40079206228256226\n",
            "Loss :  0.310756117105484\n",
            "Loss :  0.34883981943130493\n",
            "Loss :  0.26256483793258667\n",
            "Loss :  0.3421853482723236\n",
            "Loss :  0.25317004323005676\n",
            "Loss :  0.25658881664276123\n",
            "Loss :  0.2568674087524414\n",
            "Loss :  0.2868024706840515\n",
            "Loss :  0.2951534688472748\n",
            "Loss :  0.26942163705825806\n",
            "Loss :  0.20239393413066864\n",
            "Loss :  0.23585207760334015\n",
            "Loss :  0.3697455823421478\n",
            "Loss :  0.2667911946773529\n",
            "Loss :  0.24018028378486633\n",
            "Loss :  0.47876501083374023\n",
            "Loss :  0.3484867513179779\n",
            "Loss :  0.44580328464508057\n",
            "Loss :  0.38562196493148804\n",
            "Loss :  0.30757373571395874\n",
            "Loss :  0.31860730051994324\n",
            "Loss :  0.31584450602531433\n",
            "Loss :  0.3665904998779297\n",
            "Loss :  0.20155344903469086\n",
            "Loss :  0.2131308764219284\n",
            "Loss :  0.19099421799182892\n",
            "Loss :  0.30728450417518616\n",
            "Loss :  0.2598182260990143\n",
            "Loss :  0.3300737738609314\n",
            "Loss :  0.4077770709991455\n",
            "Loss :  0.2678629159927368\n",
            "Loss :  0.31318584084510803\n",
            "Epoch : 13\n",
            "Loss :  0.3216419816017151\n",
            "Loss :  0.3487637937068939\n",
            "Loss :  0.41026389598846436\n",
            "Loss :  0.22785568237304688\n",
            "Loss :  0.27886056900024414\n",
            "Loss :  0.34552690386772156\n",
            "Loss :  0.3620903193950653\n",
            "Loss :  0.27358224987983704\n",
            "Loss :  0.28274765610694885\n",
            "Loss :  0.5240517854690552\n",
            "Loss :  0.265378475189209\n",
            "Loss :  0.2987784445285797\n",
            "Loss :  0.26227787137031555\n",
            "Loss :  0.32767391204833984\n",
            "Loss :  0.4115610122680664\n",
            "Loss :  0.3577275574207306\n",
            "Loss :  0.20729060471057892\n",
            "Loss :  0.2629202604293823\n",
            "Loss :  0.3480394780635834\n",
            "Loss :  0.3291967213153839\n",
            "Epoch : 13\n",
            "Loss :  0.2914394438266754\n",
            "Loss :  0.21668106317520142\n",
            "Loss :  0.2005048543214798\n",
            "Loss :  0.24083644151687622\n",
            "Loss :  0.2797689437866211\n",
            "Loss :  0.28154057264328003\n",
            "Loss :  0.40388479828834534\n",
            "Loss :  0.30430692434310913\n",
            "Loss :  0.38627150654792786\n",
            "Loss :  0.33159616589546204\n",
            "Loss :  0.26110097765922546\n",
            "Loss :  0.28963932394981384\n",
            "Loss :  0.2972221374511719\n",
            "Loss :  0.3430745303630829\n",
            "Loss :  0.27891620993614197\n",
            "Loss :  0.2870774269104004\n",
            "Loss :  0.40556737780570984\n",
            "Loss :  0.2842321991920471\n",
            "Loss :  0.3867267668247223\n",
            "Loss :  0.3060125708580017\n",
            "Loss :  0.28441986441612244\n",
            "Loss :  0.31509822607040405\n",
            "Loss :  0.2768777310848236\n",
            "Loss :  0.25437861680984497\n",
            "Loss :  0.2687312364578247\n",
            "Loss :  0.3150787949562073\n",
            "Loss :  0.2462674230337143\n",
            "Loss :  0.23624975979328156\n",
            "Loss :  0.30568379163742065\n",
            "Loss :  0.26859602332115173\n",
            "Loss :  0.38578954339027405\n",
            "Loss :  0.28951576352119446\n",
            "Loss :  0.3138831853866577\n",
            "Loss :  0.4121050238609314\n",
            "Loss :  0.367889404296875\n",
            "Loss :  0.23769137263298035\n",
            "Loss :  0.214823916554451\n",
            "Loss :  0.36409834027290344\n",
            "Loss :  0.2504974901676178\n",
            "Loss :  0.31393542885780334\n",
            "Loss :  0.34744277596473694\n",
            "Loss :  0.31875383853912354\n",
            "Loss :  0.2738665044307709\n",
            "Loss :  0.37035760283470154\n",
            "Loss :  0.25819075107574463\n",
            "Loss :  0.24487808346748352\n",
            "Loss :  0.24205966293811798\n",
            "Loss :  0.29174843430519104\n",
            "Loss :  0.4242040514945984\n",
            "Loss :  0.33346647024154663\n",
            "Loss :  0.26918816566467285\n",
            "Loss :  0.2537049651145935\n",
            "Loss :  0.3058928847312927\n",
            "Loss :  0.2728029489517212\n",
            "Loss :  0.21713866293430328\n",
            "Loss :  0.24168701469898224\n",
            "Loss :  0.248185396194458\n",
            "Loss :  0.3352274000644684\n",
            "Loss :  0.21877755224704742\n",
            "Loss :  0.26100701093673706\n",
            "Epoch : 14\n",
            "Loss :  0.31284114718437195\n",
            "Loss :  0.30886518955230713\n",
            "Loss :  0.37388524413108826\n",
            "Loss :  0.22739775478839874\n",
            "Loss :  0.26403483748435974\n",
            "Loss :  0.3525440990924835\n",
            "Loss :  0.3931201100349426\n",
            "Loss :  0.2773280739784241\n",
            "Loss :  0.34050801396369934\n",
            "Loss :  0.48739930987358093\n",
            "Loss :  0.2870715260505676\n",
            "Loss :  0.3185749650001526\n",
            "Loss :  0.2498917579650879\n",
            "Loss :  0.32842451333999634\n",
            "Loss :  0.4091198146343231\n",
            "Loss :  0.3711682856082916\n",
            "Loss :  0.2389647513628006\n",
            "Loss :  0.26476970314979553\n",
            "Loss :  0.3574727475643158\n",
            "Loss :  0.3428584039211273\n",
            "Epoch : 14\n",
            "Loss :  0.25465577840805054\n",
            "Loss :  0.20151881873607635\n",
            "Loss :  0.3817228674888611\n",
            "Loss :  0.22040078043937683\n",
            "Loss :  0.3232322633266449\n",
            "Loss :  0.2976817190647125\n",
            "Loss :  0.2945846915245056\n",
            "Loss :  0.3543667197227478\n",
            "Loss :  0.27206018567085266\n",
            "Loss :  0.20741084218025208\n",
            "Loss :  0.2630864381790161\n",
            "Loss :  0.31523266434669495\n",
            "Loss :  0.2524948716163635\n",
            "Loss :  0.2911849617958069\n",
            "Loss :  0.21025237441062927\n",
            "Loss :  0.25750860571861267\n",
            "Loss :  0.24155858159065247\n",
            "Loss :  0.31467095017433167\n",
            "Loss :  0.22777462005615234\n",
            "Loss :  0.3577428162097931\n",
            "Loss :  0.34438055753707886\n",
            "Loss :  0.31217995285987854\n",
            "Loss :  0.25368595123291016\n",
            "Loss :  0.36286741495132446\n",
            "Loss :  0.38414621353149414\n",
            "Loss :  0.27815452218055725\n",
            "Loss :  0.2544774115085602\n",
            "Loss :  0.2860959470272064\n",
            "Loss :  0.27837511897087097\n",
            "Loss :  0.29150745272636414\n",
            "Loss :  0.24207933247089386\n",
            "Loss :  0.24409957230091095\n",
            "Loss :  0.24910910427570343\n",
            "Loss :  0.23337824642658234\n",
            "Loss :  0.3913159668445587\n",
            "Loss :  0.23737525939941406\n",
            "Loss :  0.3337212800979614\n",
            "Loss :  0.27986419200897217\n",
            "Loss :  0.2573733925819397\n",
            "Loss :  0.26764193177223206\n",
            "Loss :  0.20044273138046265\n",
            "Loss :  0.42065897583961487\n",
            "Loss :  0.2506140172481537\n",
            "Loss :  0.2571629583835602\n",
            "Loss :  0.22307801246643066\n",
            "Loss :  0.3594900965690613\n",
            "Loss :  0.43231916427612305\n",
            "Loss :  0.18667401373386383\n",
            "Loss :  0.2916800081729889\n",
            "Loss :  0.2687424123287201\n",
            "Loss :  0.2744850218296051\n",
            "Loss :  0.2933572828769684\n",
            "Loss :  0.2377728968858719\n",
            "Loss :  0.2711977958679199\n",
            "Loss :  0.25614750385284424\n",
            "Loss :  0.2693488299846649\n",
            "Loss :  0.33210939168930054\n",
            "Loss :  0.22337481379508972\n",
            "Loss :  0.3320225477218628\n",
            "Loss :  0.28047627210617065\n",
            "Epoch : 15\n",
            "Loss :  0.3122691810131073\n",
            "Loss :  0.30353617668151855\n",
            "Loss :  0.38342729210853577\n",
            "Loss :  0.21388362348079681\n",
            "Loss :  0.2593742907047272\n",
            "Loss :  0.32276976108551025\n",
            "Loss :  0.36685124039649963\n",
            "Loss :  0.27174484729766846\n",
            "Loss :  0.3060406744480133\n",
            "Loss :  0.4737291932106018\n",
            "Loss :  0.26247766613960266\n",
            "Loss :  0.29642969369888306\n",
            "Loss :  0.24313285946846008\n",
            "Loss :  0.3258499801158905\n",
            "Loss :  0.3596571981906891\n",
            "Loss :  0.3251597285270691\n",
            "Loss :  0.20213347673416138\n",
            "Loss :  0.2479378879070282\n",
            "Loss :  0.31494489312171936\n",
            "Loss :  0.34254366159439087\n",
            "Epoch : 15\n",
            "Loss :  0.33832433819770813\n",
            "Loss :  0.16097097098827362\n",
            "Loss :  0.2732483148574829\n",
            "Loss :  0.2726627588272095\n",
            "Loss :  0.2975328266620636\n",
            "Loss :  0.2685195505619049\n",
            "Loss :  0.23957034945487976\n",
            "Loss :  0.2683985233306885\n",
            "Loss :  0.29956570267677307\n",
            "Loss :  0.31682267785072327\n",
            "Loss :  0.33282655477523804\n",
            "Loss :  0.37783995270729065\n",
            "Loss :  0.2237069308757782\n",
            "Loss :  0.3049449026584625\n",
            "Loss :  0.22930145263671875\n",
            "Loss :  0.29346388578414917\n",
            "Loss :  0.21261288225650787\n",
            "Loss :  0.24541383981704712\n",
            "Loss :  0.29692575335502625\n",
            "Loss :  0.2938174307346344\n",
            "Loss :  0.23570482432842255\n",
            "Loss :  0.22480222582817078\n",
            "Loss :  0.2421216517686844\n",
            "Loss :  0.3433731198310852\n",
            "Loss :  0.21741634607315063\n",
            "Loss :  0.18183936178684235\n",
            "Loss :  0.21322090923786163\n",
            "Loss :  0.21965132653713226\n",
            "Loss :  0.23818464577198029\n",
            "Loss :  0.23671765625476837\n",
            "Loss :  0.21907706558704376\n",
            "Loss :  0.2496006041765213\n",
            "Loss :  0.22707530856132507\n",
            "Loss :  0.2978171706199646\n",
            "Loss :  0.1711224615573883\n",
            "Loss :  0.29227229952812195\n",
            "Loss :  0.26198309659957886\n",
            "Loss :  0.2598508894443512\n",
            "Loss :  0.2598731219768524\n",
            "Loss :  0.19508832693099976\n",
            "Loss :  0.27204832434654236\n",
            "Loss :  0.23273965716362\n",
            "Loss :  0.26575779914855957\n",
            "Loss :  0.20637042820453644\n",
            "Loss :  0.41410329937934875\n",
            "Loss :  0.27122676372528076\n",
            "Loss :  0.34586629271507263\n",
            "Loss :  0.23651531338691711\n",
            "Loss :  0.2821153998374939\n",
            "Loss :  0.25791773200035095\n",
            "Loss :  0.2940683960914612\n",
            "Loss :  0.3725549578666687\n",
            "Loss :  0.27927741408348083\n",
            "Loss :  0.2720743715763092\n",
            "Loss :  0.23907123506069183\n",
            "Loss :  0.33147478103637695\n",
            "Loss :  0.2349262535572052\n",
            "Loss :  0.32598939538002014\n",
            "Loss :  0.3190140128135681\n",
            "Loss :  0.4080269932746887\n",
            "Epoch : 16\n",
            "Loss :  0.3164333403110504\n",
            "Loss :  0.3649953603744507\n",
            "Loss :  0.4082779288291931\n",
            "Loss :  0.2231302261352539\n",
            "Loss :  0.28933730721473694\n",
            "Loss :  0.31836387515068054\n",
            "Loss :  0.36518993973731995\n",
            "Loss :  0.26571622490882874\n",
            "Loss :  0.28561511635780334\n",
            "Loss :  0.5051221251487732\n",
            "Loss :  0.24852986633777618\n",
            "Loss :  0.32149311900138855\n",
            "Loss :  0.2620668113231659\n",
            "Loss :  0.34460026025772095\n",
            "Loss :  0.3577894866466522\n",
            "Loss :  0.35907211899757385\n",
            "Loss :  0.17144598066806793\n",
            "Loss :  0.24382229149341583\n",
            "Loss :  0.3069070875644684\n",
            "Loss :  0.34057679772377014\n",
            "Epoch : 16\n",
            "Loss :  0.2880312204360962\n",
            "Loss :  0.23141728341579437\n",
            "Loss :  0.2041419893503189\n",
            "Loss :  0.4025900065898895\n",
            "Loss :  0.22194039821624756\n",
            "Loss :  0.4635988771915436\n",
            "Loss :  0.3213566243648529\n",
            "Loss :  0.21462246775627136\n",
            "Loss :  0.21766746044158936\n",
            "Loss :  0.33656466007232666\n",
            "Loss :  0.34272441267967224\n",
            "Loss :  0.1932740956544876\n",
            "Loss :  0.28731656074523926\n",
            "Loss :  0.27592119574546814\n",
            "Loss :  0.3213587999343872\n",
            "Loss :  0.2877648174762726\n",
            "Loss :  0.2503371238708496\n",
            "Loss :  0.2630261182785034\n",
            "Loss :  0.23966598510742188\n",
            "Loss :  0.3019588887691498\n",
            "Loss :  0.20100072026252747\n",
            "Loss :  0.23488637804985046\n",
            "Loss :  0.2952251136302948\n",
            "Loss :  0.21370179951190948\n",
            "Loss :  0.2968241572380066\n",
            "Loss :  0.26825958490371704\n",
            "Loss :  0.2986719310283661\n",
            "Loss :  0.2654191553592682\n",
            "Loss :  0.5134895443916321\n",
            "Loss :  0.3466467261314392\n",
            "Loss :  0.21276308596134186\n",
            "Loss :  0.2681545317173004\n",
            "Loss :  0.2720767557621002\n",
            "Loss :  0.26610517501831055\n",
            "Loss :  0.2815612256526947\n",
            "Loss :  0.299625039100647\n",
            "Loss :  0.39413416385650635\n",
            "Loss :  0.2065124213695526\n",
            "Loss :  0.2411525845527649\n",
            "Loss :  0.23272456228733063\n",
            "Loss :  0.32592591643333435\n",
            "Loss :  0.2725437879562378\n",
            "Loss :  0.3855589032173157\n",
            "Loss :  0.2566242814064026\n",
            "Loss :  0.2400771826505661\n",
            "Loss :  0.25734198093414307\n",
            "Loss :  0.26487085223197937\n",
            "Loss :  0.21389970183372498\n",
            "Loss :  0.3166032135486603\n",
            "Loss :  0.1946762651205063\n",
            "Loss :  0.20504970848560333\n",
            "Loss :  0.3493841886520386\n",
            "Loss :  0.24982638657093048\n",
            "Loss :  0.274978369474411\n",
            "Loss :  0.20357614755630493\n",
            "Loss :  0.3227216899394989\n",
            "Loss :  0.21707704663276672\n",
            "Loss :  0.19540756940841675\n",
            "Loss :  0.34833553433418274\n",
            "Loss :  0.2577029764652252\n",
            "Epoch : 17\n",
            "Loss :  0.31089672446250916\n",
            "Loss :  0.34402453899383545\n",
            "Loss :  0.37511083483695984\n",
            "Loss :  0.20234666764736176\n",
            "Loss :  0.25160279870033264\n",
            "Loss :  0.34026941657066345\n",
            "Loss :  0.41138091683387756\n",
            "Loss :  0.23123593628406525\n",
            "Loss :  0.30206313729286194\n",
            "Loss :  0.48798730969429016\n",
            "Loss :  0.2648649215698242\n",
            "Loss :  0.32454708218574524\n",
            "Loss :  0.25517281889915466\n",
            "Loss :  0.31876906752586365\n",
            "Loss :  0.3629263937473297\n",
            "Loss :  0.3529511094093323\n",
            "Loss :  0.21190087497234344\n",
            "Loss :  0.25235557556152344\n",
            "Loss :  0.31642967462539673\n",
            "Loss :  0.327217698097229\n",
            "Epoch : 17\n",
            "Loss :  0.2735329866409302\n",
            "Loss :  0.29763975739479065\n",
            "Loss :  0.2663215696811676\n",
            "Loss :  0.25311750173568726\n",
            "Loss :  0.21818311512470245\n",
            "Loss :  0.3395543098449707\n",
            "Loss :  0.281724750995636\n",
            "Loss :  0.2317477911710739\n",
            "Loss :  0.2565572261810303\n",
            "Loss :  0.26624876260757446\n",
            "Loss :  0.2936754524707794\n",
            "Loss :  0.3058588206768036\n",
            "Loss :  0.27917560935020447\n",
            "Loss :  0.32355940341949463\n",
            "Loss :  0.18271952867507935\n",
            "Loss :  0.21644210815429688\n",
            "Loss :  0.33246910572052\n",
            "Loss :  0.227468803524971\n",
            "Loss :  0.26083290576934814\n",
            "Loss :  0.2697671949863434\n",
            "Loss :  0.2229529470205307\n",
            "Loss :  0.25676241517066956\n",
            "Loss :  0.25196096301078796\n",
            "Loss :  0.23001156747341156\n",
            "Loss :  0.3125198781490326\n",
            "Loss :  0.24819442629814148\n",
            "Loss :  0.20914502441883087\n",
            "Loss :  0.17887844145298004\n",
            "Loss :  0.2112037092447281\n",
            "Loss :  0.30320850014686584\n",
            "Loss :  0.2124405950307846\n",
            "Loss :  0.26152777671813965\n",
            "Loss :  0.23367367684841156\n",
            "Loss :  0.1589522361755371\n",
            "Loss :  0.22775714099407196\n",
            "Loss :  0.20400555431842804\n",
            "Loss :  0.1975000500679016\n",
            "Loss :  0.23930655419826508\n",
            "Loss :  0.3570939898490906\n",
            "Loss :  0.2930854260921478\n",
            "Loss :  0.21925899386405945\n",
            "Loss :  0.22801192104816437\n",
            "Loss :  0.2594689428806305\n",
            "Loss :  0.1518879234790802\n",
            "Loss :  0.3242485821247101\n",
            "Loss :  0.4009449779987335\n",
            "Loss :  0.3528217673301697\n",
            "Loss :  0.29336848855018616\n",
            "Loss :  0.2585119307041168\n",
            "Loss :  0.2848217785358429\n",
            "Loss :  0.21461957693099976\n",
            "Loss :  0.2522937059402466\n",
            "Loss :  0.28774064779281616\n",
            "Loss :  0.25098904967308044\n",
            "Loss :  0.2828975021839142\n",
            "Loss :  0.16443930566310883\n",
            "Loss :  0.29892098903656006\n",
            "Loss :  0.30109459161758423\n",
            "Loss :  0.32295700907707214\n",
            "Loss :  0.43744149804115295\n",
            "Epoch : 18\n",
            "Loss :  0.3264743983745575\n",
            "Loss :  0.3677554726600647\n",
            "Loss :  0.40483003854751587\n",
            "Loss :  0.17234110832214355\n",
            "Loss :  0.26462191343307495\n",
            "Loss :  0.3615456819534302\n",
            "Loss :  0.39572110772132874\n",
            "Loss :  0.24123096466064453\n",
            "Loss :  0.2943526804447174\n",
            "Loss :  0.530676543712616\n",
            "Loss :  0.2578214704990387\n",
            "Loss :  0.32047271728515625\n",
            "Loss :  0.2631654143333435\n",
            "Loss :  0.3340660631656647\n",
            "Loss :  0.36627236008644104\n",
            "Loss :  0.3617764115333557\n",
            "Loss :  0.2296352982521057\n",
            "Loss :  0.28242117166519165\n",
            "Loss :  0.3639484941959381\n",
            "Loss :  0.3166305720806122\n",
            "Epoch : 18\n",
            "Loss :  0.2803683578968048\n",
            "Loss :  0.2881212830543518\n",
            "Loss :  0.21384750306606293\n",
            "Loss :  0.23471079766750336\n",
            "Loss :  0.2538052499294281\n",
            "Loss :  0.3889533281326294\n",
            "Loss :  0.23785072565078735\n",
            "Loss :  0.24887868762016296\n",
            "Loss :  0.31205204129219055\n",
            "Loss :  0.25970926880836487\n",
            "Loss :  0.24638114869594574\n",
            "Loss :  0.17803293466567993\n",
            "Loss :  0.3370636999607086\n",
            "Loss :  0.30810627341270447\n",
            "Loss :  0.2970348000526428\n",
            "Loss :  0.26452943682670593\n",
            "Loss :  0.41442638635635376\n",
            "Loss :  0.18842296302318573\n",
            "Loss :  0.23968273401260376\n",
            "Loss :  0.29947301745414734\n",
            "Loss :  0.24020282924175262\n",
            "Loss :  0.24215920269489288\n",
            "Loss :  0.20589300990104675\n",
            "Loss :  0.1633620411157608\n",
            "Loss :  0.281949520111084\n",
            "Loss :  0.3224828541278839\n",
            "Loss :  0.394610196352005\n",
            "Loss :  0.22712162137031555\n",
            "Loss :  0.23513539135456085\n",
            "Loss :  0.26903676986694336\n",
            "Loss :  0.20105382800102234\n",
            "Loss :  0.2353714555501938\n",
            "Loss :  0.21848055720329285\n",
            "Loss :  0.20383262634277344\n",
            "Loss :  0.3582509458065033\n",
            "Loss :  0.2955593466758728\n",
            "Loss :  0.29074349999427795\n",
            "Loss :  0.20944257080554962\n",
            "Loss :  0.22611947357654572\n",
            "Loss :  0.19497175514698029\n",
            "Loss :  0.364246666431427\n",
            "Loss :  0.24830590188503265\n",
            "Loss :  0.26720768213272095\n",
            "Loss :  0.23078365623950958\n",
            "Loss :  0.2228154093027115\n",
            "Loss :  0.21789200603961945\n",
            "Loss :  0.23177146911621094\n",
            "Loss :  0.2051665335893631\n",
            "Loss :  0.23558688163757324\n",
            "Loss :  0.2356337457895279\n",
            "Loss :  0.24918635189533234\n",
            "Loss :  0.23311515152454376\n",
            "Loss :  0.17188124358654022\n",
            "Loss :  0.21063286066055298\n",
            "Loss :  0.2726149559020996\n",
            "Loss :  0.29717057943344116\n",
            "Loss :  0.40424636006355286\n",
            "Loss :  0.32218071818351746\n",
            "Loss :  0.37000036239624023\n",
            "Loss :  0.19194632768630981\n",
            "Epoch : 19\n",
            "Loss :  0.33640262484550476\n",
            "Loss :  0.3306358754634857\n",
            "Loss :  0.3937586843967438\n",
            "Loss :  0.19636638462543488\n",
            "Loss :  0.2677832245826721\n",
            "Loss :  0.3266882300376892\n",
            "Loss :  0.3720480501651764\n",
            "Loss :  0.24253596365451813\n",
            "Loss :  0.3102034628391266\n",
            "Loss :  0.49721336364746094\n",
            "Loss :  0.28403440117836\n",
            "Loss :  0.34895244240760803\n",
            "Loss :  0.25284916162490845\n",
            "Loss :  0.35196590423583984\n",
            "Loss :  0.32764115929603577\n",
            "Loss :  0.39214643836021423\n",
            "Loss :  0.20495270192623138\n",
            "Loss :  0.26499345898628235\n",
            "Loss :  0.3210272789001465\n",
            "Loss :  0.3423762023448944\n",
            "Epoch : 19\n",
            "Loss :  0.20639143884181976\n",
            "Loss :  0.25540199875831604\n",
            "Loss :  0.25629159808158875\n",
            "Loss :  0.220175638794899\n",
            "Loss :  0.23203928768634796\n",
            "Loss :  0.297597736120224\n",
            "Loss :  0.22635646164417267\n",
            "Loss :  0.2223803699016571\n",
            "Loss :  0.2861432433128357\n",
            "Loss :  0.23017804324626923\n",
            "Loss :  0.30810287594795227\n",
            "Loss :  0.2716924846172333\n",
            "Loss :  0.17343948781490326\n",
            "Loss :  0.2687315046787262\n",
            "Loss :  0.2699824869632721\n",
            "Loss :  0.28555333614349365\n",
            "Loss :  0.21310196816921234\n",
            "Loss :  0.38732534646987915\n",
            "Loss :  0.34647253155708313\n",
            "Loss :  0.22607554495334625\n",
            "Loss :  0.215713232755661\n",
            "Loss :  0.3331740200519562\n",
            "Loss :  0.35845857858657837\n",
            "Loss :  0.22405549883842468\n",
            "Loss :  0.19719916582107544\n",
            "Loss :  0.3351755440235138\n",
            "Loss :  0.333504855632782\n",
            "Loss :  0.30091965198516846\n",
            "Loss :  0.23611463606357574\n",
            "Loss :  0.20546388626098633\n",
            "Loss :  0.2392512410879135\n",
            "Loss :  0.2105427384376526\n",
            "Loss :  0.27896618843078613\n",
            "Loss :  0.30410221219062805\n",
            "Loss :  0.1826249212026596\n",
            "Loss :  0.20583006739616394\n",
            "Loss :  0.28038492798805237\n",
            "Loss :  0.2877095341682434\n",
            "Loss :  0.25840452313423157\n",
            "Loss :  0.2147587686777115\n",
            "Loss :  0.18307042121887207\n",
            "Loss :  0.19265343248844147\n",
            "Loss :  0.18121561408042908\n",
            "Loss :  0.23201687633991241\n",
            "Loss :  0.2409210503101349\n",
            "Loss :  0.22945696115493774\n",
            "Loss :  0.24871842563152313\n",
            "Loss :  0.2464454472064972\n",
            "Loss :  0.37404346466064453\n",
            "Loss :  0.2523708641529083\n",
            "Loss :  0.2924829125404358\n",
            "Loss :  0.3043365180492401\n",
            "Loss :  0.23936700820922852\n",
            "Loss :  0.32764673233032227\n",
            "Loss :  0.2725180685520172\n",
            "Loss :  0.32750022411346436\n",
            "Loss :  0.24729445576667786\n",
            "Loss :  0.19666516780853271\n",
            "Loss :  0.19009776413440704\n",
            "Loss :  0.26847389340400696\n",
            "Epoch : 20\n",
            "Loss :  0.3143850266933441\n",
            "Loss :  0.3353046476840973\n",
            "Loss :  0.35203102231025696\n",
            "Loss :  0.21702568233013153\n",
            "Loss :  0.26750192046165466\n",
            "Loss :  0.37529072165489197\n",
            "Loss :  0.424767404794693\n",
            "Loss :  0.2537679076194763\n",
            "Loss :  0.33879637718200684\n",
            "Loss :  0.503545343875885\n",
            "Loss :  0.3082350194454193\n",
            "Loss :  0.3886931836605072\n",
            "Loss :  0.24752208590507507\n",
            "Loss :  0.37428978085517883\n",
            "Loss :  0.36806565523147583\n",
            "Loss :  0.4268001317977905\n",
            "Loss :  0.22481203079223633\n",
            "Loss :  0.2501138746738434\n",
            "Loss :  0.328140527009964\n",
            "Loss :  0.35151752829551697\n",
            "Epoch : 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsO7eOal5OKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "7cbe68fa-fc4a-4f0f-800e-07ebfc6fa7ce"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-160-63addaaeade9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultilabel_f1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'multilabel_f1_score' from 'sklearn.metrics' (/usr/local/lib/python3.7/dist-packages/sklearn/metrics/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo16xKetO9t6",
        "outputId": "223f1b42-3974-4262-d670-f85f6ec5ae71"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"使用デバイス：\", device)\n",
        "print('-----start-------')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "-----start-------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE6ciHH03i5f"
      },
      "source": [
        "inputs_pre = torch.zeros(512)\n",
        "inputs_pre = inputs_pre.cuda()\n",
        "#inputs_pre = inputs_pre.cpu()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bJGQN_aF0AK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377a342e-03fb-4220-f6a2-4e8c3643cb2e"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labels_numpy = 0\n",
        "preds_numpy = 0\n",
        "\n",
        "aa = []\n",
        "bb = []\n",
        "\n",
        "# テストデータでの正解率を求める\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_trained.eval()   # モデルを検証モードに\n",
        "net_trained.to(device)  # GPUが使えるならGPUへ送る\n",
        "\n",
        "# epochの正解数を記録する変数\n",
        "epoch_corrects = 0\n",
        "\n",
        "a = [[0, 0],\n",
        "     [0, 0]]\n",
        "\n",
        "for batch in tqdm(dl_test):  # testデータのDataLoader\n",
        "    # batchはTextとLableの辞書オブジェクト\n",
        "    # GPUが使えるならGPUにデータを送る\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = batch.Text[0].to(device)  # 文章\n",
        "    labels = batch.Label.to(device)  # ラベル\n",
        "    labels2 = batch.Label2.to(device)\n",
        "    labels3 = batch.Label3.to(device)\n",
        "    labels4 = batch.Label4.to(device)\n",
        "    labels5 = batch.Label5.to(device)\n",
        "    labels6 = batch.Label6.to(device)\n",
        "    labels7 = batch.Label7.to(device)\n",
        "    labels8 = batch.Label8.to(device)\n",
        "    labels9 = batch.Label9.to(device)\n",
        "    labels10 = batch.Label10.to(device)\n",
        "    labels11 = batch.Label11.to(device)\n",
        "    labels12 = batch.Label12.to(device)\n",
        "    pa = torch.stack([labels, labels2, labels3, labels4, labels5,labels6,labels7,labels8,labels9,labels10, labels11, labels12], dim = 1)\n",
        "                \n",
        "    pa = torch.tensor(pa, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    # 順伝搬（forward）計算\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        # BertForReviewに入力\n",
        "        outputs = net_trained(inputs)\n",
        "\n",
        "        loss = criterion(outputs, pa)  # 損失を計算\n",
        "                  \n",
        "        #epoch_corrects += torch.sum(preds == pa.data)  # 正解数の合計を更新\n",
        "\n",
        "#ラベルとoutputsを入手\n",
        "        labels_numpy = pa.cpu().numpy()\n",
        "        outputs_numpy = outputs.cpu().numpy()\n",
        "\n",
        "        aa = np.append(aa,labels_numpy)\n",
        "        bb = np.append(bb,outputs_numpy)\n",
        "\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "100%|██████████| 20/20 [00:09<00:00,  2.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfNZgNk-Q_Kl",
        "outputId": "d4d2e5ef-2c43-4531-a722-3a5dd2485cb0"
      },
      "source": [
        "loss"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2825, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IeNlERRastY",
        "outputId": "ba17283e-5c00-4540-fe54-279427423063"
      },
      "source": [
        "float(loss)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28252431750297546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9hEYEs3Njo9",
        "outputId": "1053471a-b22d-4cb2-8a6a-cad94f0cb29b"
      },
      "source": [
        "bb"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.61596155, -8.42434692, -4.29112244, ..., -3.89150071,\n",
              "       -2.82455182, -5.77447128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfHH3VbuunpU",
        "outputId": "8affb695-bf6a-46c0-e9f9-17ae2c47b842"
      },
      "source": [
        "sum(bb)/len(bb)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2.862694364940075"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOs5bnRwOklJ",
        "outputId": "568a5a4a-d9fe-4fb0-db9e-671d606cdc8e"
      },
      "source": [
        "max(bb)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.119914531707764"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SXGywUJBjSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0d40a8-e93e-489e-e9c0-671c3af9af82"
      },
      "source": [
        "#正解ラベル\n",
        "aa\n",
        "aa1 = aa.reshape(240, 12)\n",
        "aa1.shape\n",
        "aa1 = np.array(aa1)\n",
        "aa1"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2w_Qi5Xin04"
      },
      "source": [
        "hani = [-0.5 , -0.49, -0.48, -0.47, -0.46, -0.45, -0.44, -0.43, -0.42,\n",
        "       -0.41, -0.4 , -0.39, -0.38, -0.37, -0.36, -0.35, -0.34, -0.33,\n",
        "       -0.32, -0.31, -0.3 , -0.29, -0.28, -0.27, -0.26, -0.25, -0.24,\n",
        "       -0.23, -0.22, -0.21, -0.2 , -0.19, -0.18, -0.17, -0.16, -0.15,\n",
        "       -0.14, -0.13, -0.12, -0.11, -0.1 , -0.09, -0.08, -0.07, -0.06,\n",
        "       -0.05, -0.04, -0.03, -0.02, -0.01]"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_896jLSWhTmk",
        "outputId": "58f45390-6937-4628-f2ba-0ded7e90c009"
      },
      "source": [
        "hani = np.array(hani)\n",
        "\n",
        "bb1 = np.array(bb1)\n",
        "bb1.shape"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2880,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVxNyuWFg-SO"
      },
      "source": [
        "bb1 = bb\n",
        "for i in range(0, len(bb1)):\n",
        "  if bb1[i] >  -0.1:\n",
        "    bb1[i] = 1\n",
        "  else:\n",
        "    bb1[i] = 0 "
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19w7Lkuv-SKu",
        "outputId": "bb593678-3748-48a8-f30b-ee7852f10186"
      },
      "source": [
        "for i in range(0, len(y)):\n",
        "  print(i, y[i])"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "1 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "2 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "3 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "4 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "5 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "7 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "8 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "10 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "11 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "12 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "13 [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "14 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "15 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "16 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "17 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "18 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "19 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "20 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "21 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "22 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            "23 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "24 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "25 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "26 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "27 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "28 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "29 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "30 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "31 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "32 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "33 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "34 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "35 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "36 [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "37 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "38 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "39 [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "40 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
            "41 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "42 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "43 [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "44 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "45 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "46 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "47 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "48 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "49 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "50 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "51 [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
            "52 [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
            "53 [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "54 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "55 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "56 [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "57 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "58 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "59 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "60 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "61 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "62 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "63 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "64 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "65 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "66 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "67 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "68 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "69 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "70 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "71 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "72 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "73 [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "74 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "75 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "76 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "77 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "78 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "79 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "80 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "81 [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
            "82 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "83 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "84 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "85 [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "86 [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "87 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "88 [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "89 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "90 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
            "91 [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
            "92 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "93 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "94 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "95 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "96 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "97 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "98 [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "99 [1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
            "100 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "101 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "102 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
            "103 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "104 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            "105 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "106 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "107 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "108 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "109 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "110 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "111 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
            "112 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "113 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
            "114 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            "115 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "116 [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "117 [1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
            "118 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "119 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "120 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "121 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "122 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "123 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "124 [0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
            "125 [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "126 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "127 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "128 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "129 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "130 [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "131 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "132 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "133 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "134 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            "135 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "136 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "137 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "138 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "139 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "140 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "141 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "142 [1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
            "143 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "144 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            "145 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "146 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "147 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "148 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "149 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "150 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "151 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "152 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "153 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "154 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "155 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            "156 [1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "157 [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "158 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "159 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "160 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "161 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "162 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "163 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "164 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "165 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "166 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "167 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "168 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "169 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "170 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "171 [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "172 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
            "173 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "174 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "175 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "176 [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "177 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "178 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "179 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
            "180 [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "181 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "182 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "183 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "184 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "185 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "186 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "187 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "188 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "189 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "190 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "191 [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "192 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "193 [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
            "194 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "195 [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
            "196 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "197 [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "198 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "199 [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "200 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "201 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "202 [0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "203 [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            "204 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "205 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "206 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "207 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "208 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "209 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "210 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "211 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "212 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
            "213 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "214 [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "215 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "216 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "217 [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "218 [0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "219 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "220 [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "221 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "222 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "223 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "224 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "225 [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "226 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "227 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "228 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "229 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "230 [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "231 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "232 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            "233 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "234 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "235 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "236 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "237 [1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            "238 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "239 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXvfbwePhpa"
      },
      "source": [
        "y = bb1.reshape(240, 12)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG2ASFJbPPLW",
        "outputId": "77eaa756-7639-4b12-b265-c0b21312e54c"
      },
      "source": [
        "x1 = 0\n",
        "x2 = 0\n",
        "x3 = 0\n",
        "x4 = 0\n",
        "x = aa1\n",
        "for i in range(0, 240):\n",
        "   for j in  range(0, 12):\n",
        "     if x[i][j] == y[i][j]:\n",
        "       if x[i][j] == 1:\n",
        "         x1 = x1 + 1\n",
        "       else:\n",
        "         x2 = x2 + 1\n",
        "     if x[i][j] != y[i][j]:\n",
        "       if x[i][j] == 1:\n",
        "         x3 = x3 + 1\n",
        "       else:\n",
        "         x4 = x4 + 1\n",
        "print(\"1を1と当てた：\",x1)\n",
        "print(\"0を0と当てた：\",x2)\n",
        "print(\"1を0と間違えた：\",x3)\n",
        "print(\"0を1と間違えた：\",x4)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1を1と当てた： 188\n",
            "0を0と当てた： 2368\n",
            "1を0と間違えた： 167\n",
            "0を1と間違えた： 157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlWhP34cRYr4",
        "outputId": "05d7a863-b92a-4137-9cfb-6b405e306c77"
      },
      "source": [
        "x = aa1\n",
        "ln = []\n",
        "for j in range(0, 12):\n",
        "  x1 = 0\n",
        "  x2 = 0\n",
        "  x3 = 0\n",
        "  x4 = 0\n",
        "    \n",
        "  for i in  range(0, 240):\n",
        "    if x[i][j] == y[i][j]:\n",
        "      if x[i][j] == 1:\n",
        "         x1 = x1 + 1\n",
        "      else:\n",
        "         x2 = x2 + 1\n",
        "    if x[i][j] != y[i][j]:\n",
        "       if x[i][j] == 1:\n",
        "         x3 = x3 + 1\n",
        "       else:\n",
        "         x4 = x4 + 1\n",
        "  ln.append(x1)\n",
        "  ln.append(x2)\n",
        "  ln.append(x3)\n",
        "  ln.append(x4)\n",
        "  print(\"何列目か：\", j)     \n",
        "  print(\"1を1と当てた：\",x1)\n",
        "  print(\"0を0と当てた：\",x2)\n",
        "  print(\"1を0と間違えた：\",x3)\n",
        "  print(\"0を1と間違えた：\",x4)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "何列目か： 0\n",
            "1を1と当てた： 36\n",
            "0を0と当てた： 162\n",
            "1を0と間違えた： 8\n",
            "0を1と間違えた： 34\n",
            "何列目か： 1\n",
            "1を1と当てた： 0\n",
            "0を0と当てた： 229\n",
            "1を0と間違えた： 8\n",
            "0を1と間違えた： 3\n",
            "何列目か： 2\n",
            "1を1と当てた： 30\n",
            "0を0と当てた： 181\n",
            "1を0と間違えた： 7\n",
            "0を1と間違えた： 22\n",
            "何列目か： 3\n",
            "1を1と当てた： 4\n",
            "0を0と当てた： 222\n",
            "1を0と間違えた： 7\n",
            "0を1と間違えた： 7\n",
            "何列目か： 4\n",
            "1を1と当てた： 45\n",
            "0を0と当てた： 145\n",
            "1を0と間違えた： 29\n",
            "0を1と間違えた： 21\n",
            "何列目か： 5\n",
            "1を1と当てた： 3\n",
            "0を0と当てた： 199\n",
            "1を0と間違えた： 34\n",
            "0を1と間違えた： 4\n",
            "何列目か： 6\n",
            "1を1と当てた： 22\n",
            "0を0と当てた： 192\n",
            "1を0と間違えた： 5\n",
            "0を1と間違えた： 21\n",
            "何列目か： 7\n",
            "1を1と当てた： 0\n",
            "0を0と当てた： 237\n",
            "1を0と間違えた： 3\n",
            "0を1と間違えた： 0\n",
            "何列目か： 8\n",
            "1を1と当てた： 16\n",
            "0を0と当てた： 178\n",
            "1を0と間違えた： 22\n",
            "0を1と間違えた： 24\n",
            "何列目か： 9\n",
            "1を1と当てた： 0\n",
            "0を0と当てた： 214\n",
            "1を0と間違えた： 26\n",
            "0を1と間違えた： 0\n",
            "何列目か： 10\n",
            "1を1と当てた： 31\n",
            "0を0と当てた： 180\n",
            "1を0と間違えた： 10\n",
            "0を1と間違えた： 19\n",
            "何列目か： 11\n",
            "1を1と当てた： 1\n",
            "0を0と当てた： 229\n",
            "1を0と間違えた： 8\n",
            "0を1と間違えた： 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQIfLk3JV7lO",
        "outputId": "a8233eee-4e8a-48de-9968-8c0a39ba9e6b"
      },
      "source": [
        "acc2 = sum(y == aa1)\n",
        "#各ラベルの正解率\n",
        "acc2/240"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.825     , 0.95416667, 0.87916667, 0.94166667, 0.79166667,\n",
              "       0.84166667, 0.89166667, 0.9875    , 0.80833333, 0.89166667,\n",
              "       0.87916667, 0.95833333])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baSL8WbR8Tkq"
      },
      "source": [
        "cm = multilabel_confusion_matrix(aa1, y)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "604LY2Tu5oz7"
      },
      "source": [
        "for j in range(0, 50):\n",
        "  bb1 =bb\n",
        "  for i in range(0, len(bb1)):\n",
        "    if bb1[i] >  hani[j]:\n",
        "      bb1[i] = 1\n",
        "    else:\n",
        "      bb1[i] = 0  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}